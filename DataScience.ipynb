{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmvig\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd ; import numpy as np; import random as rnd ;import math\n",
    "#importing data visualization packages\n",
    "import seaborn as sns ; import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#importing machine learning packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import display, Math, Latex\n",
    "import os; import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "from colorama import Fore, Back, Style \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scattertext as st\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import sys                                                    #Causes problems with regression in skikitlearn \n",
    "#reload(sys)                                                   #later on. Find different way to make Count Vectorizer\n",
    "#sys.setdefaultencoding('utf8')                                #work. In future be carefull making global changes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scattertext in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0.2.43)\n",
      "Requirement already satisfied: numpy in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (1.14.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (0.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (1.11.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (0.19.1)\n",
      "Requirement already satisfied: mock in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scattertext) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas->scattertext) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas->scattertext) (2018.4)\n",
      "Requirement already satisfied: pbr>=0.11 in c:\\users\\jaya3225\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mock->scattertext) (5.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scattertext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_13_chgenro - data2013_y1 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y1.csv\")\n",
    "data2013_y1.head(3)\n",
    "data2013_y1.shape\n",
    "pred2013_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y1.csv\")\n",
    "pred2013_y1.head(3)\n",
    "pred2013_y1.shape\n",
    "xtrainy1=pd.DataFrame(data2013_y1.values[:,1:27])\n",
    "xtesty1=pd.DataFrame(pred2013_y1.values[:,1:27])\n",
    "ytrainy1=pd.DataFrame(data2013_y1.values[:,27])\n",
    "ytesty1=pd.DataFrame(pred2013_y1.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrainy1, ytrainy1)\n",
    "y_mody1=rfr.predict(xtesty1)\n",
    "y_mody1\n",
    "#y_mody1=pd.DataFrame(y_mody1)\n",
    "#y_mody1.to_csv('pred13_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_13_Fracdeg - data2013_y2 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19867122, 0.13957749, 0.14947818, 0.18784815, 0.15789508,\n",
       "       0.35092555, 0.2185944 , 0.19570669, 0.1995777 , 0.17574816,\n",
       "       0.26931017, 0.25924837, 0.18652526, 0.21595516, 0.27010545,\n",
       "       0.23240362, 0.3214524 , 0.29013995, 0.22669816, 0.17678784,\n",
       "       0.18565337, 0.24083074, 0.21480156, 0.24015658, 0.24822103,\n",
       "       0.20134578, 0.19332459, 0.33538697, 0.24245847, 0.23808982,\n",
       "       0.23670343, 0.16092742, 0.27237684, 0.22996645, 0.15498116,\n",
       "       0.23622612, 0.20136976, 0.20188475, 0.35468804, 0.40379754,\n",
       "       0.26592192, 0.23172724, 0.19943325, 0.15946862, 0.14712584,\n",
       "       0.20976272, 0.1324057 , 0.16611673, 0.1921724 , 0.16214023,\n",
       "       0.16966591, 0.19487746, 0.17571992, 0.2001713 , 0.22562974,\n",
       "       0.22322969, 0.19970707, 0.1341697 , 0.16794026, 0.1914314 ,\n",
       "       0.2247776 , 0.28213342, 0.18514283, 0.18409889, 0.17680207,\n",
       "       0.21964233, 0.19522739, 0.22620753, 0.21755384, 0.1621881 ,\n",
       "       0.20084776, 0.23579002, 0.17986274, 0.17705043, 0.21501666,\n",
       "       0.18011535, 0.22483757, 0.1743188 , 0.1584388 , 0.16610195,\n",
       "       0.21138046, 0.13451933, 0.15312941, 0.16659947, 0.12701924,\n",
       "       0.22329855, 0.22899468, 0.20543122, 0.22171561, 0.18822731,\n",
       "       0.27213081, 0.24788661, 0.19915496, 0.14934752, 0.20971631,\n",
       "       0.20274471, 0.1906338 , 0.19974939, 0.24606453, 0.23215562,\n",
       "       0.18628649, 0.20804761, 0.17942465, 0.21364651, 0.23079701,\n",
       "       0.15490256, 0.19618226, 0.18402561, 0.22160797, 0.21833458,\n",
       "       0.24455327, 0.16912215, 0.22744135, 0.14824054, 0.16282453,\n",
       "       0.19243794, 0.21498819, 0.14595862, 0.16791201, 0.1863019 ,\n",
       "       0.19258271, 0.20578567, 0.21808438, 0.17086426, 0.18362451,\n",
       "       0.20962445, 0.21522871, 0.22041294, 0.17351056, 0.18890747,\n",
       "       0.14725635, 0.22036555, 0.18566587, 0.21509439, 0.19319627,\n",
       "       0.23929578, 0.16002875, 0.2415683 , 0.23120129, 0.23023523,\n",
       "       0.23071806, 0.22003961, 0.07535155, 0.22847801, 0.2847797 ,\n",
       "       0.22614338, 0.20254742, 0.0876392 , 0.29939129, 0.22585992,\n",
       "       0.18692924, 0.15768296, 0.27771932, 0.26545138, 0.18530023,\n",
       "       0.24184812, 0.15838417, 0.13128863, 0.1602119 , 0.21763913,\n",
       "       0.22150053, 0.20434033, 0.20925202, 0.1930779 , 0.21407288,\n",
       "       0.13151339, 0.34372239, 0.05675421, 0.16544133, 0.18936925,\n",
       "       0.16832662, 0.22236161, 0.14955219, 0.19663191, 0.1818232 ,\n",
       "       0.18929209, 0.21167654, 0.19948953, 0.1980442 , 0.19848451,\n",
       "       0.23759884, 0.1993628 , 0.20998351, 0.17553547, 0.20352904,\n",
       "       0.06517326, 0.21110837, 0.21563352, 0.15438291, 0.19418841,\n",
       "       0.17883017, 0.22215187, 0.19219149, 0.38172037, 0.19327488,\n",
       "       0.19606386, 0.22417833, 0.20540137, 0.22883034, 0.21854143,\n",
       "       0.276331  , 0.16282933, 0.21055739, 0.22503803, 0.2371573 ,\n",
       "       0.35815817, 0.17884298, 0.16022088, 0.15999147, 0.29162965,\n",
       "       0.17559101, 0.20323847, 0.18168456, 0.18404357, 0.19447395,\n",
       "       0.13195065, 0.18937369, 0.17947916, 0.17992602, 0.10612807,\n",
       "       0.14603347, 0.22589265, 0.19263453, 0.16521877, 0.13364457,\n",
       "       0.15830089, 0.19714915, 0.19873293, 0.22106525, 0.21405988,\n",
       "       0.16376981, 0.19431502, 0.18418685, 0.1586913 , 0.20901091,\n",
       "       0.22859289, 0.17100994, 0.17236612, 0.24510117, 0.22200504,\n",
       "       0.24001172, 0.18393495, 0.24572914, 0.20378207, 0.20415397,\n",
       "       0.2283468 , 0.18432304, 0.2180133 , 0.1995015 , 0.15213544,\n",
       "       0.2016642 , 0.13228646, 0.12041764, 0.18668859, 0.19121702,\n",
       "       0.19039769, 0.15243478, 0.1122375 , 0.17886795, 0.14403628,\n",
       "       0.19286936, 0.20702459, 0.1868593 , 0.16456538, 0.24359594,\n",
       "       0.12393299, 0.11733662, 0.07870035, 0.24395778, 0.21990974,\n",
       "       0.18345967, 0.32318169, 0.19847525, 0.21493399, 0.17569161,\n",
       "       0.19199114, 0.22262997, 0.17113057, 0.23937633, 0.16613571,\n",
       "       0.37197695, 0.20363235, 0.19295615, 0.17244809, 0.22360661,\n",
       "       0.11943119, 0.11180907, 0.13806934, 0.16238015, 0.1848533 ,\n",
       "       0.18304754, 0.18552389, 0.19698672, 0.15244369, 0.19257634,\n",
       "       0.17344408, 0.18101038])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y2.csv\")\n",
    "data2013_y2.head(3)\n",
    "data2013_y2.shape\n",
    "pred2013_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y2.csv\")\n",
    "pred2013_y2.head(3)\n",
    "pred2013_y2.shape\n",
    "xtrainy2=pd.DataFrame(data2013_y2.values[:,1:27])\n",
    "xtesy2=pd.DataFrame(pred2013_y2.values[:,1:27])\n",
    "ytrainy2=pd.DataFrame(data2013_y2.values[:,27])\n",
    "ytesty2=pd.DataFrame(pred2013_y2.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrainy2, ytrainy2)\n",
    "y_mody2=rfr.predict(xtesy2)\n",
    "y_mody2\n",
    "#y_mody2=pd.DataFrame(y_mody2)\n",
    "#y_mody2.to_csv('pred13_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NUID</th>\n",
       "      <th>SATREAD</th>\n",
       "      <th>SATMATH</th>\n",
       "      <th>ACTCUM</th>\n",
       "      <th>CARNIGIE</th>\n",
       "      <th>AVGSALMALE</th>\n",
       "      <th>AVGSALWOM</th>\n",
       "      <th>AVGSALTOT</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>...</th>\n",
       "      <th>FEEINS</th>\n",
       "      <th>TUITOUT</th>\n",
       "      <th>FEEOUT</th>\n",
       "      <th>FOOTBALL</th>\n",
       "      <th>TUITPER</th>\n",
       "      <th>SLCTVTY</th>\n",
       "      <th>APPEAL</th>\n",
       "      <th>RSRCHPSTU</th>\n",
       "      <th>HIGHBP</th>\n",
       "      <th>FRACDEGRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>830</td>\n",
       "      <td>450</td>\n",
       "      <td>450</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>7438</td>\n",
       "      <td>6567</td>\n",
       "      <td>7079</td>\n",
       "      <td>0.803</td>\n",
       "      <td>...</td>\n",
       "      <td>1590</td>\n",
       "      <td>11184</td>\n",
       "      <td>1590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300903</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.042123</td>\n",
       "      <td>1427.97515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4829</td>\n",
       "      <td>640</td>\n",
       "      <td>650</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>11106</td>\n",
       "      <td>9149</td>\n",
       "      <td>10170</td>\n",
       "      <td>0.803</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061987</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.247772</td>\n",
       "      <td>12581.25524</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.206029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4370</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6942</td>\n",
       "      <td>6216</td>\n",
       "      <td>6557</td>\n",
       "      <td>0.803</td>\n",
       "      <td>...</td>\n",
       "      <td>1784</td>\n",
       "      <td>13872</td>\n",
       "      <td>1784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298823</td>\n",
       "      <td>50.434783</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>302.61442</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.121203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  NUID  SATREAD  SATMATH  ACTCUM  CARNIGIE  AVGSALMALE  \\\n",
       "0           1   830      450      450      19        18        7438   \n",
       "1           2  4829      640      650      28        15       11106   \n",
       "2           3  4370      480      480      19        18        6942   \n",
       "\n",
       "   AVGSALWOM  AVGSALTOT  HOUSE    ...      FEEINS  TUITOUT  FEEOUT  FOOTBALL  \\\n",
       "0       6567       7079  0.803    ...        1590    11184    1590       0.0   \n",
       "1       9149      10170  0.803    ...           0    16398       0       0.0   \n",
       "2       6216       6557  0.803    ...        1784    13872    1784       0.0   \n",
       "\n",
       "    TUITPER    SLCTVTY    APPEAL    RSRCHPSTU  HIGHBP  FRACDEGRE  \n",
       "0  0.300903   0.862019  0.042123   1427.97515     0.0   0.151279  \n",
       "1  0.061987   0.857143  0.247772  12581.25524    45.9   0.206029  \n",
       "2  0.298823  50.434783  0.166379    302.61442    40.6   0.121203  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y2.csv\")\n",
    "data2013_y2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7438.0</td>\n",
       "      <td>6567.0</td>\n",
       "      <td>7079.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>5592.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>11184.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>0.300903</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.042123</td>\n",
       "      <td>1427.975150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11106.0</td>\n",
       "      <td>9149.0</td>\n",
       "      <td>10170.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061987</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.247772</td>\n",
       "      <td>12581.255240</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.206029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6942.0</td>\n",
       "      <td>6216.0</td>\n",
       "      <td>6557.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>6936.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>13872.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>0.298823</td>\n",
       "      <td>50.434783</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>302.614420</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.121203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10826.0</td>\n",
       "      <td>8073.0</td>\n",
       "      <td>9605.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>9450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397032</td>\n",
       "      <td>0.496386</td>\n",
       "      <td>2.186893</td>\n",
       "      <td>1486.405400</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.193176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7669.0</td>\n",
       "      <td>6582.0</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>24300.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.755230</td>\n",
       "      <td>2.340720</td>\n",
       "      <td>85.810627</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.132027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>620.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>8083.0</td>\n",
       "      <td>9429.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>24768.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>0.359702</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>3.268817</td>\n",
       "      <td>4810.748596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>630.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7625.0</td>\n",
       "      <td>7325.0</td>\n",
       "      <td>7513.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>0.289269</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>3.774194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.239650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>6347.0</td>\n",
       "      <td>5645.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>11150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690547</td>\n",
       "      <td>0.800244</td>\n",
       "      <td>0.536641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.333938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>6292.0</td>\n",
       "      <td>6027.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>20742.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>20742.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.373727</td>\n",
       "      <td>5.540741</td>\n",
       "      <td>0.290775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5570.0</td>\n",
       "      <td>5221.0</td>\n",
       "      <td>5512.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>8952.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>8952.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.153803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>538.079646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>640.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5581.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>14620.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>14620.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.232539</td>\n",
       "      <td>0.693503</td>\n",
       "      <td>1.885947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6688.0</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>6408.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>13020.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.499587</td>\n",
       "      <td>0.940193</td>\n",
       "      <td>0.579981</td>\n",
       "      <td>57.179223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>590.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5856.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>5909.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.706454</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>610.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>5024.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>17970.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>17970.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.793561</td>\n",
       "      <td>0.344471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.167608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>613.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7433.0</td>\n",
       "      <td>6647.0</td>\n",
       "      <td>7035.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>9330.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>19020.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>5.992537</td>\n",
       "      <td>13.518380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>565.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7553.0</td>\n",
       "      <td>6768.0</td>\n",
       "      <td>7152.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>5592.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>11184.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>0.417376</td>\n",
       "      <td>0.787743</td>\n",
       "      <td>2.047438</td>\n",
       "      <td>8.775858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>513.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5587.0</td>\n",
       "      <td>5035.0</td>\n",
       "      <td>5307.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>15258.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>15258.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.408108</td>\n",
       "      <td>2.082988</td>\n",
       "      <td>0.440239</td>\n",
       "      <td>484.670793</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.179734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>630.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9091.0</td>\n",
       "      <td>7378.0</td>\n",
       "      <td>8261.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>25528.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>25528.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.516313</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>1.369902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.258986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>550.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7757.0</td>\n",
       "      <td>6672.0</td>\n",
       "      <td>7212.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>6648.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>13296.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.144159</td>\n",
       "      <td>0.855688</td>\n",
       "      <td>0.295635</td>\n",
       "      <td>1579.642398</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.170270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6056.0</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>29054.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>29054.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>0.373488</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>0.855198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.178760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>4428.0</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.557190</td>\n",
       "      <td>0.980994</td>\n",
       "      <td>0.381520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>450.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4593.0</td>\n",
       "      <td>4867.0</td>\n",
       "      <td>4743.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>13548.0</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>13548.0</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>0.459962</td>\n",
       "      <td>0.399621</td>\n",
       "      <td>1.021327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.123646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6351.0</td>\n",
       "      <td>5582.0</td>\n",
       "      <td>5996.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>0.908</td>\n",
       "      <td>...</td>\n",
       "      <td>6336.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>12672.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.513907</td>\n",
       "      <td>0.737037</td>\n",
       "      <td>0.344724</td>\n",
       "      <td>10.492665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3317.0</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>1.012658</td>\n",
       "      <td>0.391071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.386033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>600.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11067.0</td>\n",
       "      <td>9083.0</td>\n",
       "      <td>10320.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>9388.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>26070.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.257635</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>1.864078</td>\n",
       "      <td>11047.071650</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.207779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>630.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>8052.0</td>\n",
       "      <td>8387.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>30120.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>30120.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555256</td>\n",
       "      <td>3.466019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>5494.0</td>\n",
       "      <td>5473.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>7842.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>7842.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>0.928911</td>\n",
       "      <td>4.780731</td>\n",
       "      <td>0.368311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.133658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>580.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8437.0</td>\n",
       "      <td>7276.0</td>\n",
       "      <td>7863.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>9640.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>14229.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>0.375074</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.913415</td>\n",
       "      <td>806.064501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>640.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4330.0</td>\n",
       "      <td>4169.0</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>28320.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>28320.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>0.764354</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>6694.0</td>\n",
       "      <td>7480.0</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1.123</td>\n",
       "      <td>...</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>15302.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>0.295816</td>\n",
       "      <td>5.330739</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>1030.870131</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.149092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>-1.308</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>1.541</td>\n",
       "      <td>...</td>\n",
       "      <td>19998.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>19998.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>0.905532</td>\n",
       "      <td>0.701550</td>\n",
       "      <td>1.723757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.917</td>\n",
       "      <td>...</td>\n",
       "      <td>16760.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>16760.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>0.028</td>\n",
       "      <td>...</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353565</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.631778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7522.0</td>\n",
       "      <td>7522.0</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>1.307</td>\n",
       "      <td>...</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267544</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.644457</td>\n",
       "      <td>1.054217</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>550.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>8687.0</td>\n",
       "      <td>7253.0</td>\n",
       "      <td>7938.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>16574.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>0.097961</td>\n",
       "      <td>0.571792</td>\n",
       "      <td>1.062222</td>\n",
       "      <td>4844.154506</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.178796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>5105.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>0.208597</td>\n",
       "      <td>0.321059</td>\n",
       "      <td>0.315412</td>\n",
       "      <td>23.593135</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.114511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7045.0</td>\n",
       "      <td>6083.0</td>\n",
       "      <td>6875.0</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754808</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.136033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5308.0</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>5405.0</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-1.701</td>\n",
       "      <td>1.655</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808968</td>\n",
       "      <td>0.660592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.190005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>5876.0</td>\n",
       "      <td>6223.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>0.742</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.3</td>\n",
       "      <td>0.191774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>6660.0</td>\n",
       "      <td>6794.0</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>0.396</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649725</td>\n",
       "      <td>0.575053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.147482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5599.0</td>\n",
       "      <td>5823.0</td>\n",
       "      <td>5655.0</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.917</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.197183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5681.0</td>\n",
       "      <td>5418.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>0.916</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788301</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.111826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7322.0</td>\n",
       "      <td>6710.0</td>\n",
       "      <td>7186.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.976</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801115</td>\n",
       "      <td>0.486079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.172113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6481.0</td>\n",
       "      <td>6025.0</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.676</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.449405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5609.0</td>\n",
       "      <td>0.851</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>0.960</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717781</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.158537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7019.0</td>\n",
       "      <td>6841.0</td>\n",
       "      <td>6962.0</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>1.307</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844914</td>\n",
       "      <td>0.499404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.184422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6609.0</td>\n",
       "      <td>6557.0</td>\n",
       "      <td>6588.0</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>0.682</td>\n",
       "      <td>...</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834620</td>\n",
       "      <td>0.626831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>570.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5636.0</td>\n",
       "      <td>5347.0</td>\n",
       "      <td>5492.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>3282.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>11747.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>0.286079</td>\n",
       "      <td>0.733248</td>\n",
       "      <td>0.466493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4502.0</td>\n",
       "      <td>4434.0</td>\n",
       "      <td>4458.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.976</td>\n",
       "      <td>...</td>\n",
       "      <td>27050.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>27050.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.478814</td>\n",
       "      <td>3.056047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>490.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>8138.0</td>\n",
       "      <td>6515.0</td>\n",
       "      <td>7134.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>1.263</td>\n",
       "      <td>...</td>\n",
       "      <td>7570.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711621</td>\n",
       "      <td>0.133065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.122601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11009.0</td>\n",
       "      <td>9881.0</td>\n",
       "      <td>10541.0</td>\n",
       "      <td>-1.308</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>1.541</td>\n",
       "      <td>...</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.287435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>4072.0</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>0.396</td>\n",
       "      <td>...</td>\n",
       "      <td>16230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897528</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>0.302026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.194690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6489.0</td>\n",
       "      <td>6305.0</td>\n",
       "      <td>6312.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>0.654</td>\n",
       "      <td>...</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>0.900861</td>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.271447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5407.0</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>5215.0</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>14980.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>14980.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.848390</td>\n",
       "      <td>0.981699</td>\n",
       "      <td>0.276964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.229751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>6519.0</td>\n",
       "      <td>6532.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.976</td>\n",
       "      <td>...</td>\n",
       "      <td>16150.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>16150.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735511</td>\n",
       "      <td>0.320917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.182692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4759.0</td>\n",
       "      <td>4623.0</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.976</td>\n",
       "      <td>...</td>\n",
       "      <td>16533.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>16533.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>8.282609</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8694.0</td>\n",
       "      <td>7150.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>1.307</td>\n",
       "      <td>...</td>\n",
       "      <td>4440.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>14376.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>0.434762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.667815</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.229528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>550.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5271.0</td>\n",
       "      <td>5405.0</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>1.307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.484536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1     2     3        4       5        6      7      8      9   \\\n",
       "0     450.0  450.0  19.0  18.0   7438.0  6567.0   7079.0  0.803 -0.474  0.908   \n",
       "1     640.0  650.0  28.0  15.0  11106.0  9149.0  10170.0  0.803 -0.474  0.908   \n",
       "2     480.0  480.0  19.0  18.0   6942.0  6216.0   6557.0  0.803 -0.474  0.908   \n",
       "3     620.0  640.0  30.0  16.0  10826.0  8073.0   9605.0  0.803 -0.474  0.908   \n",
       "4     550.0  540.0  23.0  18.0   7669.0  6582.0   7173.0  0.803 -0.474  0.908   \n",
       "5     620.0  650.0  30.0  16.0  10201.0  8083.0   9429.0  0.803 -0.474  0.908   \n",
       "6     630.0  640.0  29.0  21.0   7625.0  7325.0   7513.0  0.803 -0.474  0.908   \n",
       "7     550.0  540.0  25.0  22.0   4477.0  6347.0   5645.0  0.803 -0.474  0.908   \n",
       "8     500.0  540.0  24.0  22.0   5774.0  6292.0   6027.0  0.803 -0.474  0.908   \n",
       "9     550.0  540.0  25.0  24.0   5570.0  5221.0   5512.0  0.803 -0.474  0.908   \n",
       "10    640.0  600.0  24.0  21.0   5581.0  5700.0   5638.0  0.803 -0.474  0.908   \n",
       "11    550.0  540.0  22.0  18.0   6688.0  6141.0   6408.0  0.803 -0.474  0.908   \n",
       "12    590.0  600.0  26.0   1.0   5856.0  6015.0   5909.0  0.803 -0.474  0.908   \n",
       "13    610.0  680.0  25.0  22.0   5151.0  4900.0   5024.0  0.803 -0.474  0.908   \n",
       "14    613.0  550.0  26.0  19.0   7433.0  6647.0   7035.0  0.803 -0.474  0.908   \n",
       "15    565.0  530.0  25.0  18.0   7553.0  6768.0   7152.0  0.803 -0.474  0.908   \n",
       "16    513.0  510.0  22.0  22.0   5587.0  5035.0   5307.0  0.803 -0.474  0.908   \n",
       "17    630.0  610.0  28.0  19.0   9091.0  7378.0   8261.0  0.803 -0.474  0.908   \n",
       "18    550.0  565.0  26.0  16.0   7757.0  6672.0   7212.0  0.803 -0.474  0.908   \n",
       "19    600.0  600.0  27.0  20.0   6056.0  6057.0   6057.0  0.803 -0.474  0.908   \n",
       "20    550.0  540.0  25.0  24.0   4602.0  4428.0   4577.0  0.803 -0.474  0.908   \n",
       "21    450.0  438.0  20.0  21.0   4593.0  4867.0   4743.0  0.803 -0.474  0.908   \n",
       "22    550.0  540.0  24.0  18.0   6351.0  5582.0   5996.0  0.803 -0.474  0.908   \n",
       "23    550.0  540.0  25.0  10.0   3317.0  3658.0   3613.0  0.771 -1.411  1.263   \n",
       "24    600.0  630.0  27.0  15.0  11067.0  9083.0  10320.0  0.771 -1.411  1.263   \n",
       "25    630.0  650.0  29.0  22.0   8470.0  8052.0   8387.0  0.771 -1.411  1.263   \n",
       "26    550.0  540.0  25.0  18.0   5444.0  5494.0   5473.0  0.771 -1.411  1.263   \n",
       "27    580.0  580.0  25.0  16.0   8437.0  7276.0   7863.0  0.771 -1.411  1.263   \n",
       "28    640.0  600.0  30.0  20.0   4330.0  4169.0   4248.0  0.771 -1.411  1.263   \n",
       "29    480.0  480.0  27.0  17.0   8041.0  6694.0   7480.0  0.678  0.136  1.123   \n",
       "...     ...    ...   ...   ...      ...     ...      ...    ...    ...    ...   \n",
       "1460  550.0  540.0  25.0  -3.0      0.0  4167.0   4167.0 -1.061 -1.387 -0.003   \n",
       "1461  550.0  540.0  25.0  -3.0      0.0  2633.0   2633.0 -1.308 -1.669  1.541   \n",
       "1462  550.0  540.0  25.0  -3.0      0.0  6511.0   6511.0  0.843 -0.500  0.917   \n",
       "1463  550.0  540.0  25.0  -3.0   2750.0     0.0   2750.0 -0.905 -0.998  0.028   \n",
       "1464  550.0  540.0  25.0  -3.0      0.0  7522.0   7522.0  1.042 -1.077  1.307   \n",
       "1465  550.0  540.0  25.0  -3.0   2295.0     0.0   2295.0 -1.061 -1.387 -0.003   \n",
       "1466  550.0  560.0  23.0  -3.0   8687.0  7253.0   7938.0  0.809 -0.772  0.921   \n",
       "1467  550.0  540.0  25.0  -3.0   5233.0  4975.0   5105.0  0.809 -0.772  0.921   \n",
       "1468  550.0  540.0  25.0  -3.0   7045.0  6083.0   6875.0 -1.061 -1.387 -0.003   \n",
       "1469  550.0  540.0  25.0  -3.0   5308.0  5622.0   5405.0 -1.200 -1.701  1.655   \n",
       "1470  550.0  540.0  25.0  -3.0   6360.0  5876.0   6223.0  0.573 -1.050  0.742   \n",
       "1471  550.0  540.0  25.0  -3.0   6860.0  6660.0   6794.0 -0.190 -0.931  0.396   \n",
       "1472  550.0  540.0  25.0  -3.0   5599.0  5823.0   5655.0  0.843 -0.500  0.917   \n",
       "1473  550.0  540.0  25.0  -3.0   5681.0  5418.0   5606.0  0.760 -0.725  0.916   \n",
       "1474  550.0  540.0  25.0  -3.0   7322.0  6710.0   7186.0  0.808 -0.736  0.976   \n",
       "1475  550.0  540.0  25.0  -3.0   6481.0  6025.0   6291.0  0.376 -0.655  0.676   \n",
       "1476  550.0  540.0  25.0  -3.0   5609.0     0.0   5609.0  0.851 -0.611  0.960   \n",
       "1477  550.0  540.0  25.0  -3.0   7019.0  6841.0   6962.0  1.042 -1.077  1.307   \n",
       "1478  550.0  540.0  25.0  -3.0   6609.0  6557.0   6588.0  0.617 -0.859  0.682   \n",
       "1479  570.0  560.0  24.0  -3.0   5636.0  5347.0   5492.0  0.809 -0.772  0.921   \n",
       "1480  550.0  540.0  25.0  -3.0   4502.0  4434.0   4458.0  0.808 -0.736  0.976   \n",
       "1481  490.0  490.0  21.0  -3.0   8138.0  6515.0   7134.0  0.771 -1.411  1.263   \n",
       "1482  550.0  540.0  25.0  18.0  11009.0  9881.0  10541.0 -1.308 -1.669  1.541   \n",
       "1483  550.0  540.0  25.0  23.0   4038.0  4072.0   4059.0 -0.190 -0.931  0.396   \n",
       "1484  550.0  540.0  25.0  26.0   6489.0  6305.0   6312.0  0.411 -0.984  0.654   \n",
       "1485  550.0  540.0  25.0   9.0   5407.0  5175.0   5215.0 -1.061 -1.387 -0.003   \n",
       "1486  550.0  540.0  22.0   9.0   6600.0  6519.0   6532.0  0.808 -0.736  0.976   \n",
       "1487  550.0  540.0  25.0  10.0   4759.0  4623.0   4640.0  0.808 -0.736  0.976   \n",
       "1488  550.0  540.0  25.0  18.0   8694.0  7150.0   7972.0  1.042 -1.077  1.307   \n",
       "1489  550.0  540.0  25.0  -3.0   5271.0  5405.0   5376.0  1.042 -1.077  1.307   \n",
       "\n",
       "        ...          15      16       17      18        19         20  \\\n",
       "0       ...      5592.0  1590.0  11184.0  1590.0  0.300903   0.862019   \n",
       "1       ...      7206.0     0.0  16398.0     0.0  0.061987   0.857143   \n",
       "2       ...      6936.0  1784.0  13872.0  1784.0  0.298823  50.434783   \n",
       "3       ...      9450.0     0.0  23950.0     0.0  0.397032   0.496386   \n",
       "4       ...      8100.0   650.0  24300.0   650.0  0.362608   0.755230   \n",
       "5       ...      8256.0  1596.0  24768.0  1596.0  0.359702   0.581250   \n",
       "6       ...     29600.0  1090.0  29600.0  1090.0  0.289269   0.329787   \n",
       "7       ...     11150.0     0.0  11150.0     0.0  0.690547   0.800244   \n",
       "8       ...     20742.0   999.0  20742.0   999.0  0.373727   5.540741   \n",
       "9       ...      8952.0   840.0   8952.0   840.0  0.153803   1.000000   \n",
       "10      ...     14620.0  1010.0  14620.0  1010.0  0.232539   0.693503   \n",
       "11      ...      6510.0  1150.0  13020.0  1150.0  0.499587   0.940193   \n",
       "12      ...      6000.0  2570.0  12000.0  2570.0  0.085903   0.706454   \n",
       "13      ...     17970.0   970.0  17970.0   970.0  0.508889   0.793561   \n",
       "14      ...      9330.0   670.0  19020.0   670.0  0.346971   0.590308   \n",
       "15      ...      5592.0  1486.0  11184.0  1486.0  0.417376   0.787743   \n",
       "16      ...     15258.0   978.0  15258.0   978.0  0.408108   2.082988   \n",
       "17      ...     25528.0   800.0  25528.0   800.0  0.516313   0.774510   \n",
       "18      ...      6648.0   300.0  13296.0   300.0  0.144159   0.855688   \n",
       "19      ...     29054.0  1870.0  29054.0  1870.0  0.373488   0.572644   \n",
       "20      ...     11700.0   450.0  11700.0   450.0  0.557190   0.980994   \n",
       "21      ...     13548.0  2317.0  13548.0  2317.0  0.459962   0.399621   \n",
       "22      ...      6336.0   940.0  12672.0   940.0  0.513907   0.737037   \n",
       "23      ...         0.0     0.0      0.0     0.0  0.087700   1.012658   \n",
       "24      ...      9388.0  1003.0  26070.0  1003.0  0.257635   0.741007   \n",
       "25      ...     30120.0   914.0  30120.0   914.0  0.000000   0.555256   \n",
       "26      ...      7842.0   703.0   7842.0   703.0  0.928911   4.780731   \n",
       "27      ...      9640.0   867.0  14229.0   867.0  0.375074   0.906077   \n",
       "28      ...     28320.0  1412.0  28320.0  1412.0  0.764354   0.760000   \n",
       "29      ...      5525.0  1569.0  15302.0  1569.0  0.295816   5.330739   \n",
       "...     ...         ...     ...      ...     ...       ...        ...   \n",
       "1460    ...      5250.0  2075.0   5250.0  2075.0  0.000000   1.000000   \n",
       "1461    ...     19998.0  2340.0  19998.0  2340.0  0.905532   0.701550   \n",
       "1462    ...     16760.0   600.0  16760.0   600.0  0.000000   0.003759   \n",
       "1463    ...     11500.0     0.0  11500.0     0.0  0.353565   0.993734   \n",
       "1464    ...     24600.0    75.0  24600.0    75.0  0.000000   0.267544   \n",
       "1465    ...      9300.0   300.0   9300.0   300.0  0.644457   1.054217   \n",
       "1466    ...      4670.0  1434.0  16574.0  1434.0  0.097961   0.571792   \n",
       "1467    ...      2334.0   992.0   8621.0   992.0  0.208597   0.321059   \n",
       "1468    ...     16076.0    80.0  16076.0    80.0  0.000000   0.754808   \n",
       "1469    ...     16076.0    80.0  16076.0    80.0  0.000000   0.808968   \n",
       "1470    ...     16076.0    80.0  16076.0    80.0  0.000000   0.717445   \n",
       "1471    ...     16076.0    80.0  16076.0    80.0  0.000000   0.649725   \n",
       "1472    ...     16076.0    80.0  16076.0    80.0  0.000000   0.780645   \n",
       "1473    ...     16076.0    80.0  16076.0    80.0  0.000000   0.788301   \n",
       "1474    ...     16076.0    80.0  16076.0    80.0  0.000000   0.801115   \n",
       "1475    ...     16076.0    80.0  16076.0    80.0  0.000000   0.811594   \n",
       "1476    ...     16076.0    80.0  16076.0    80.0  0.000000   0.717781   \n",
       "1477    ...     16076.0    80.0  16076.0    80.0  0.000000   0.844914   \n",
       "1478    ...     16076.0    80.0  16076.0    80.0  0.000000   0.834620   \n",
       "1479    ...      3282.0  1176.0  11747.0  1176.0  0.286079   0.733248   \n",
       "1480    ...     27050.0   455.0  27050.0   455.0  0.014387   0.478814   \n",
       "1481    ...      7570.0   296.0  10913.0   296.0  0.000000   0.711621   \n",
       "1482    ...     14400.0     0.0  14400.0     0.0  0.862264   1.000000   \n",
       "1483    ...     16230.0     0.0  16230.0     0.0  0.897528   0.830275   \n",
       "1484    ...     16771.0  2058.0  16771.0  2058.0  0.900861   0.490750   \n",
       "1485    ...     14980.0   320.0  14980.0   320.0  0.848390   0.981699   \n",
       "1486    ...     16150.0  1465.0  16150.0  1465.0  0.000000   0.735511   \n",
       "1487    ...     16533.0   873.0  16533.0   873.0  0.995604   8.282609   \n",
       "1488    ...      4440.0  1266.0  14376.0  1266.0  0.434762   1.000000   \n",
       "1489    ...         0.0     0.0      0.0     0.0  0.997019   1.000000   \n",
       "\n",
       "            21            22    23        24  \n",
       "0     0.042123   1427.975150   0.0  0.151279  \n",
       "1     0.247772  12581.255240  45.9  0.206029  \n",
       "2     0.166379    302.614420  40.6  0.121203  \n",
       "3     2.186893   1486.405400  40.0  0.193176  \n",
       "4     2.340720     85.810627  40.6  0.132027  \n",
       "5     3.268817   4810.748596   0.0  0.221111  \n",
       "6     3.774194      0.000000  45.9  0.239650  \n",
       "7     0.536641      0.000000  45.9  0.333938  \n",
       "8     0.290775      0.000000  40.6  0.161458  \n",
       "9     1.000000    538.079646   0.0  0.079646  \n",
       "10    1.885947      0.000000   0.0  0.147208  \n",
       "11    0.579981     57.179223   0.0  0.183981  \n",
       "12    0.406680      0.000000   0.0  0.195652  \n",
       "13    0.344471      0.000000  43.0  0.167608  \n",
       "14    5.992537     13.518380   0.0  0.150488  \n",
       "15    2.047438      8.775858   0.0  0.152663  \n",
       "16    0.440239    484.670793  36.7  0.179734  \n",
       "17    1.369902      0.000000  45.9  0.258986  \n",
       "18    0.295635   1579.642398  43.0  0.170270  \n",
       "19    0.855198      0.000000  43.0  0.178760  \n",
       "20    0.381520      0.000000  45.9  0.115385  \n",
       "21    1.021327      0.000000  40.0  0.123646  \n",
       "22    0.344724     10.492665   0.0  0.166753  \n",
       "23    0.391071      0.000000  28.9  0.386033  \n",
       "24    1.864078  11047.071650  29.6  0.207779  \n",
       "25    3.466019      0.000000   0.0  0.181187  \n",
       "26    0.368311      0.000000  28.9  0.133658  \n",
       "27    0.913415    806.064501   0.0  0.219518  \n",
       "28    0.975610      0.000000   0.0  0.230943  \n",
       "29    0.670073   1030.870131  38.2  0.149092  \n",
       "...        ...           ...   ...       ...  \n",
       "1460  1.000000      0.000000   0.0  0.423077  \n",
       "1461  1.723757      0.000000   0.0  0.171429  \n",
       "1462  1.000000      0.000000  32.9  0.000000  \n",
       "1463  0.631778      0.000000   0.0  0.279070  \n",
       "1464  0.010929      0.000000  34.9  0.000000  \n",
       "1465  0.640000      0.000000   0.0  0.044444  \n",
       "1466  1.062222   4844.154506  41.9  0.178796  \n",
       "1467  0.315412     23.593135  44.0  0.114511  \n",
       "1468  0.496815      0.000000  30.7  0.136033  \n",
       "1469  0.660592      0.000000  25.1  0.190005  \n",
       "1470  0.493151      0.000000  31.3  0.191774  \n",
       "1471  0.575053      0.000000  31.5  0.147482  \n",
       "1472  0.533058      0.000000  32.9  0.197183  \n",
       "1473  0.671378      0.000000  34.7  0.111826  \n",
       "1474  0.486079      0.000000  34.4  0.172113  \n",
       "1475  0.449405      0.000000   0.0  0.181525  \n",
       "1476  0.511364      0.000000  42.2  0.158537  \n",
       "1477  0.499404      0.000000  31.9  0.184422  \n",
       "1478  0.626831      0.000000   0.0  0.208762  \n",
       "1479  0.466493      0.000000   0.0  0.121785  \n",
       "1480  3.056047      0.000000   0.0  0.000000  \n",
       "1481  0.133065      0.000000  25.6  0.122601  \n",
       "1482  1.000000      0.000000  25.9  0.287435  \n",
       "1483  0.302026      0.000000  33.0  0.194690  \n",
       "1484  0.005952      0.000000  30.0  0.271447  \n",
       "1485  0.276964      0.000000  34.5  0.229751  \n",
       "1486  0.320917      0.000000  36.9  0.182692  \n",
       "1487  0.555118      0.000000   0.0  0.373687  \n",
       "1488  1.000000    187.667815  35.1  0.229528  \n",
       "1489  1.000000      0.000000  34.9  0.484536  \n",
       "\n",
       "[1490 rows x 25 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrainy2=pd.DataFrame(data2013_y2.values[:,[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25,26,27]])\n",
    "xtrainy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0021085 , 0.0021085 , 0.0021085 , 0.00342826, 0.00165289,\n",
       "       0.00312036, 0.0021085 , 0.00165289, 0.00082645, 0.00391851,\n",
       "       0.00641341, 0.00492155, 0.00507055, 0.00341942, 0.00341942,\n",
       "       0.00442952, 0.0037885 , 0.0083747 , 0.00461495, 0.0051052 ,\n",
       "       0.00641341, 0.0037885 , 0.00341942, 0.0037885 , 0.0070562 ,\n",
       "       0.00529062, 0.00461495, 0.00739063, 0.0037885 , 0.00296205,\n",
       "       0.0051052 , 0.0042441 , 0.00428052, 0.00082645, 0.00406928,\n",
       "       0.00165113, 0.00064103, 0.00183655, 0.00545022, 0.00545022,\n",
       "       0.00165113, 0.00064103, 0.00315325, 0.0013167 , 0.0010101 ,\n",
       "       0.0010101 , 0.00425294, 0.00082645, 0.00474496, 0.00082645,\n",
       "       0.0010101 , 0.00229215, 0.00229215, 0.00296382, 0.00195195,\n",
       "       0.00195195, 0.00363773, 0.00457686, 0.00476228, 0.00213737,\n",
       "       0.00314747, 0.00476228, 0.00509671, 0.00360308, 0.00363773,\n",
       "       0.00326865, 0.00491129, 0.00296382, 0.00232857, 0.00214315,\n",
       "       0.00296382, 0.00259298, 0.00213737, 0.00251222, 0.0010101 ,\n",
       "       0.00410393, 0.00251222, 0.0031186 , 0.00443836, 0.00195773,\n",
       "       0.0010101 , 0.00195773, 0.0021085 , 0.00165113, 0.00281882,\n",
       "       0.00082645, 0.0010101 , 0.0010101 , 0.0010101 , 0.00493038,\n",
       "       0.00214315, 0.00410393, 0.0010101 , 0.0021085 , 0.00165289,\n",
       "       0.00296959, 0.00229392, 0.00428759, 0.00165289, 0.00146747,\n",
       "       0.0010101 , 0.00165113, 0.0021085 , 0.0023268 , 0.00293494,\n",
       "       0.00361062, 0.00274952, 0.00274952, 0.00278417, 0.00379427,\n",
       "       0.00229392, 0.00575506, 0.00259875, 0.00128205, 0.0052648 ,\n",
       "       0.00507938, 0.00183655, 0.00064103, 0.00428759, 0.00315501,\n",
       "       0.00165289, 0.00229215, 0.00146747, 0.0031186 , 0.00229215,\n",
       "       0.00168578, 0.00165113, 0.00296959, 0.00214315, 0.00082645,\n",
       "       0.00082645, 0.00296783, 0.00259875, 0.00165113, 0.00406045,\n",
       "       0.0040951 , 0.00525597, 0.00442952, 0.0037885 , 0.00424587,\n",
       "       0.00641341, 0.00360484, 0.01345649, 0.01214828, 0.00492155,\n",
       "       0.0051052 , 0.00622975, 0.01071228, 0.00446417, 0.00593165,\n",
       "       0.00473613, 0.00473613, 0.00604433, 0.0051052 , 0.00442952,\n",
       "       0.00446417, 0.00442952, 0.00406045, 0.00406045, 0.00341942,\n",
       "       0.00341942, 0.00637876, 0.00637876, 0.00341942, 0.00637876,\n",
       "       0.00709428, 0.00442952, 0.00727794, 0.01345649, 0.00425294,\n",
       "       0.00229215, 0.00064103, 0.00511403, 0.00165113, 0.00082645,\n",
       "       0.00296959, 0.00391851, 0.00150212, 0.00064103, 0.00293494,\n",
       "       0.00082645, 0.00146747, 0.00511403, 0.0010101 , 0.00247757,\n",
       "       0.00859549, 0.00251222, 0.00082645, 0.0010101 , 0.00341942,\n",
       "       0.0042441 , 0.00165113, 0.0021085 , 0.00315325, 0.00428759,\n",
       "       0.0021085 , 0.00165113, 0.00183655, 0.00428759, 0.00165113,\n",
       "       0.00410393, 0.00064103, 0.0021085 , 0.0010101 , 0.00082645,\n",
       "       0.00312036, 0.00195773, 0.00082645, 0.00128205, 0.00724919,\n",
       "       0.0023268 , 0.00391851, 0.00150212, 0.00064103, 0.00082645,\n",
       "       0.00428935, 0.0023268 , 0.00168578, 0.00410393, 0.00165113,\n",
       "       0.00229215, 0.0023268 , 0.00529945, 0.00082645, 0.00064103,\n",
       "       0.00493038, 0.00165113, 0.00082645, 0.00082645, 0.00165289,\n",
       "       0.00183655, 0.00082645, 0.00165113, 0.00064103, 0.00168578,\n",
       "       0.00165113, 0.0021085 , 0.00195773, 0.00165289, 0.00507938,\n",
       "       0.00146747, 0.00128205, 0.00493038, 0.00507938, 0.00390968,\n",
       "       0.00360308, 0.00064103, 0.00165289, 0.00493038, 0.00229215,\n",
       "       0.00443836, 0.00229215, 0.00064103, 0.00214315, 0.00357597,\n",
       "       0.00357597, 0.00474496, 0.00146747, 0.0021085 , 0.00251222,\n",
       "       0.0021085 , 0.00296959, 0.0021085 , 0.00906822, 0.00774846,\n",
       "       0.00443836, 0.00165113, 0.00627667, 0.00341942, 0.0021085 ,\n",
       "       0.00507938, 0.005897  , 0.00406045, 0.00082645, 0.00692202,\n",
       "       0.0031186 , 0.0040951 , 0.00262763, 0.00410393, 0.0070562 ,\n",
       "       0.00536866, 0.00424587, 0.00424587, 0.00315325, 0.00410393,\n",
       "       0.00972982, 0.00229392, 0.00410393, 0.00723986, 0.01214828,\n",
       "       0.00709085, 0.00361062, 0.00424587, 0.00278417, 0.00165289,\n",
       "       0.00473613, 0.00492155])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y2.csv\")\n",
    "data2013_y2.head(3)\n",
    "data2013_y2.shape\n",
    "pred2013_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y2.csv\")\n",
    "pred2013_y2.head(3)\n",
    "pred2013_y2.shape\n",
    "xtrainy2=pd.DataFrame(data2013_y2.values[:,[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25,26,27]])\n",
    "xtesy2=pd.DataFrame(pred2013_y2.values[:,[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25,26,27]])\n",
    "ytrainy2=pd.DataFrame(data2013_y2.values[:,27])\n",
    "ytesty2=pd.DataFrame(pred2013_y2.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrainy2, ytrainy2)\n",
    "y_mody2=rfr.predict(xtesy2)\n",
    "y_mody2\n",
    "#y_mody2=pd.DataFrame(y_mody2)\n",
    "#y_mody2.to_csv('pred13_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_13_RETPCNT - data2013_y3 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86.2, 11.2,  0. , 33. ,  0. , 28.8, 86.5, 75.5, 84.2, 77.2,  7.3,\n",
       "       97.6,  0. ,  0. , 92.6,  0. ,  5.6,  0. ,  0. ,  0. , 51.8, 85.8,\n",
       "       85.9,  0. , 94. , 33.6,  0. , 28. , 72.3, 83.2,  0. ,  7.3, 97.2,\n",
       "       81.6,  0. , 79.7,  8.1, 38.2, 22.4, 22.4, 85.5, 93.3,  0. ,  0. ,\n",
       "       33.8,  0. ,  0. , 11.2, 33. , 11.2,  0. , 59.4,  0. , 62. , 85. ,\n",
       "        7.7, 57.7, 20.5,  0. , 35.8,  0. , 97. , 83.3, 64.7, 74.3,  7.2,\n",
       "       78.1, 92.8, 74.8,  7.7, 86.2, 87.2,  0. ,  0. ,  0. ,  0. ,  7.5,\n",
       "        7.2,  6.7,  0. ,  0. ,  0. , 63.6,  0. ,  0. ,  0. , 88.6, 84.8,\n",
       "        0. , 38.2, 97.5, 20.5, 85.9, 40. , 80. , 85.2, 87.7, 79.9, 93.6,\n",
       "       88. , 82.4, 78.7,  0. ,  0. , 78.3,  0. ,  0. ,  0. , 38. ,  0. ,\n",
       "       91.1,  0. , 87.3, 16.8, 69. , 78.5,  6.9,  0. ,  4.4,  0. , 83. ,\n",
       "       92.2, 62.7, 80.7, 61.1, 91.5,  0. , 32.9,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. , 87.6, 16.8, 82.7, 87.6, 80.5,  0. ,  0. , 20.9,\n",
       "       11.2, 97.5, 80. , 85.6,  0. , 16.8, 11.2,  0. ,  0. , 95.4, 40.3,\n",
       "        0. , 84.8, 76.7,  0. ,  0. , 93.1, 87.9, 84.2, 39.2, 90.8, 78.3,\n",
       "        0. , 16.8,  0. ,  6.7,  0. , 11.2, 91.9,  0. ,  0. , 73.4,  0. ,\n",
       "       33.5,  0. , 85.5, 34.9, 90.1,  0. , 33.3, 33.7, 43. , 25.7, 39.4,\n",
       "       88.3,  0. , 40.5,  6.7, 69.4, 22.9,  0. ,  0. ,  0. , 65.6, 69.7,\n",
       "        0. ,  0. , 93.8, 18.3,  0. , 38.4, 87.8, 22.4, 72.9, 69.2,  0. ,\n",
       "        0. ,  0. ,  5.8,  0. ,  0. ,  6.5,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "       69.3, 80.8, 62.3, 34.1, 11.2, 11.2, 35.3,  0. , 88.2, 87.3,  0. ,\n",
       "        0. ,  0. , 29.3, 11.2, 77. ,  0. ,  6.4, 84.1, 77.9, 91.6, 65.7,\n",
       "       87.1, 85.5, 66.7, 88.1,  0. ,  7.4,  6.9,  0. , 75.5, 11.2, 11.2,\n",
       "        0. ,  0. , 71.4,  6.7, 18.5, 38.2,  0. , 57.4, 34.8,  6.5, 16.8,\n",
       "       33.6, 16.8, 16.8,  5.6, 10. ,  0. , 67.6, 28. ,  9.4, 95.3, 16.8,\n",
       "       57.3, 76. ,  0. ,  0. ,  0. , 22.4,  5.6,  5.6,  0. ,  0. , 33.6,\n",
       "        5.6, 11.2,  0. ,  0. ,  0. ,  0. , 11.2, 11.2,  0. ,  0. ,  0. ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y3.csv\")\n",
    "data2013_y3.head(3)\n",
    "data2013_y3.shape\n",
    "pred2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y3.csv\")\n",
    "pred2013_y3.head(3)\n",
    "pred2013_y3.shape\n",
    "xtrainy3=pd.DataFrame(data2013_y3.values[:,1:27])\n",
    "xtesty3=pd.DataFrame(pred2013_y3.values[:,1:27])\n",
    "ytrainy3=pd.DataFrame(data2013_y3.values[:,27])\n",
    "ytesty3=pd.DataFrame(pred2013_y3.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrainy3, ytrainy3)\n",
    "y_mody3=rfr.predict(xtesty3)\n",
    "y_mody3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 1.6, 1.6, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.4,\n",
       "       1.6, 0. , 0. , 0. , 2.4, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.8, 4. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 4.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.8, 0. , 0. ,\n",
       "       0. , 4. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 1.6, 1.6, 0. , 0. , 1.6, 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 1.6, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 4. ,\n",
       "       0. , 0. , 0.8, 4.8, 1.6, 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y3.csv\")\n",
    "data2013_y3.head(3)\n",
    "data2013_y3.shape\n",
    "pred2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y3.csv\")\n",
    "pred2013_y3.head(3)\n",
    "pred2013_y3.shape\n",
    "xtrainy3=pd.DataFrame(data2013_y3.values[:,2:27])\n",
    "xtesty3=pd.DataFrame(pred2013_y3.values[:,2:27])\n",
    "ytrainy3=pd.DataFrame(data2013_y3.values[:,27])\n",
    "ytesty3=pd.DataFrame(pred2013_y3.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrainy3, ytrainy3)\n",
    "y_mody3=rfr.predict(xtesty3)\n",
    "y_mody3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_13_RETPCNT - data2013_y3 - bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86.6,  0. ,  0. , 11.6,  0. , 39.6, 85.1, 51.1, 86.8, 75.9,  0. ,\n",
       "       97.1,  0. ,  0. , 92.7,  0. , 11.2,  0. ,  0. ,  0. , 15.4, 87.7,\n",
       "       85.1,  7.9, 94.6,  6. ,  0. , 22.4, 54.9, 85. ,  8.2,  0. , 97. ,\n",
       "       83.4,  0. , 76.2,  0. ,  7. , 22.4, 28. , 85. , 93.1,  0. ,  0. ,\n",
       "       11.6,  0. ,  0. ,  0. , 15.6,  0. ,  0. , 37.2,  0. , 36.6, 86.8,\n",
       "        0. , 39. , 13.6,  0. ,  8.1,  7.9, 96.8, 82.5, 41.1, 79.5,  0. ,\n",
       "       75.7, 93.4, 78.2,  0. , 82.4, 89.9,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. , 66. ,  0. ,  0. ,  9.6, 87.7, 87.2,\n",
       "        7.9,  7.3, 96.7, 17.3, 88. , 37.6, 79.8, 82.6, 85.7, 79.7, 94.4,\n",
       "       90.8, 81.4, 76.2,  0. ,  0. , 80.1,  0. ,  0. ,  0. , 16.1,  0. ,\n",
       "       90.5,  0. , 87.7, 11.2, 69.2, 80.7,  0. ,  0. ,  0. ,  0. , 85. ,\n",
       "       89. , 38.9, 81.8, 45.5, 90.7,  0. ,  7.9,  0. ,  0. ,  0. ,  7.5,\n",
       "        0. ,  0. ,  0. , 88.5, 11.2, 84.8, 86.5, 81.3,  7.5,  9.4, 13.2,\n",
       "       22.4, 97.1, 84.3, 83.1,  0. , 11.2,  0. ,  0. ,  0. , 94.4,  8.1,\n",
       "        0. , 85.1, 70.8,  0. ,  0. , 92.2, 87.2, 82.8,  8.7, 90.3, 77.2,\n",
       "        0. , 11.2,  0. ,  0. ,  0. ,  0. , 90.9,  0. ,  0. , 73. ,  0. ,\n",
       "        7.9,  0. , 85.2,  6.9, 88.3,  0. ,  7. ,  7.3, 15.5, 14.7,  6. ,\n",
       "       85.6,  0. ,  8.4,  0. , 56.2, 14.4,  0. ,  7.8,  0. , 40.3, 58.1,\n",
       "        0. ,  7.5, 92.4,  0. ,  0. ,  8.4, 88.6, 22.4, 59.9, 63.9,  0. ,\n",
       "        0. ,  0. ,  5.6,  8.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "       69.9, 87. , 47.4,  7.6,  0. ,  0. ,  8.3,  0. , 90.3, 86.3,  0. ,\n",
       "        0. ,  0. , 14.2,  0. , 79.2,  0. ,  0. , 85. , 80.9, 92.2, 51. ,\n",
       "       85.5, 87.7, 78.7, 86.3,  0. ,  0. ,  0. ,  0. , 76.4,  0. ,  0. ,\n",
       "        7.7,  0. , 56.7,  0. , 14.8,  8.4,  0. , 52.2,  7.9,  0. , 11.2,\n",
       "       28. , 11.2, 11.2, 11.2,  0. ,  0. , 54.6, 22.4,  0. , 95.8, 11.2,\n",
       "       41.7, 58.3,  0. ,  0. ,  0. , 28. , 13.5, 13.5,  5.6,  5.6, 28. ,\n",
       "       16.8,  5.6,  5.6,  5.6,  5.6,  5.6,  5.6,  5.6,  5.6,  5.6,  5.6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y3.csv\")\n",
    "data2013_y3.head(3)\n",
    "data2013_y3.shape\n",
    "pred2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y3.csv\")\n",
    "pred2013_y3.head(3)\n",
    "pred2013_y3.shape\n",
    "xtrain_13y3=pd.DataFrame(data2013_y3.values[:,1:27])\n",
    "xtest_13y3=pd.DataFrame(pred2013_y3.values[:,1:27])\n",
    "ytrain_13y3=pd.DataFrame(data2013_y3.values[:,27])\n",
    "ytest_13y3=pd.DataFrame(pred2013_y3.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_13y3, ytrain_13y3)\n",
    "y_mod_13y3 = bingr.predict(xtest_13y3)\n",
    "y_mod_13y3\n",
    "#y_mody_13y3=pd.DataFrame(y_mod_13y3)\n",
    "#y_mody_13y3.to_csv('pred13_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2013_y3.csv\")\n",
    "data2013_y3.head(3)\n",
    "data2013_y3.shape\n",
    "pred2013_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_13y3.csv\")\n",
    "pred2013_y3.head(3)\n",
    "pred2013_y3.shape\n",
    "xtrain_13y3=pd.DataFrame(data2013_y3.values[:,2:27])\n",
    "xtest_13y3=pd.DataFrame(pred2013_y3.values[:,2:27])\n",
    "ytrain_13y3=pd.DataFrame(data2013_y3.values[:,27])\n",
    "ytest_13y3=pd.DataFrame(pred2013_y3.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_13y3, ytrain_13y3)\n",
    "y_mod_13y3 = bingr.predict(xtest_13y3)\n",
    "y_mod_13y3\n",
    "y_mody_13y3=pd.DataFrame(y_mod_13y3)\n",
    "y_mody_13y3.to_csv('pred13_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_14_Chgenro - data2014_y1  - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y1.csv\")\n",
    "data2014_y1.head(3)\n",
    "data2014_y1.shape\n",
    "pred2014_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y1.csv\")\n",
    "pred2014_y1.head(3)\n",
    "pred2014_y1.shape\n",
    "xtrain_14y1=pd.DataFrame(data2014_y1.values[:,1:30])\n",
    "xtest_14y1=pd.DataFrame(pred2014_y1.values[:,1:30])\n",
    "ytrain_14y1=pd.DataFrame(data2014_y1.values[:,30])\n",
    "ytest_14y1=pd.DataFrame(pred2014_y1.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_14y1, ytrain_14y1)\n",
    "y_mod_14y1=rfr.predict(xtest_14y1)\n",
    "y_mod_14y1\n",
    "y_mod_14y1=pd.DataFrame(y_mod_14y1)\n",
    "y_mod_14y1.to_csv('pred14_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y1.csv\")\n",
    "data2014_y1.head(3)\n",
    "data2014_y1.shape\n",
    "pred2014_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y1.csv\")\n",
    "pred2014_y1.head(3)\n",
    "pred2014_y1.shape\n",
    "xtrain_14y1=pd.DataFrame(data2014_y1.values[:,2:30])\n",
    "xtest_14y1=pd.DataFrame(pred2014_y1.values[:,2:30])\n",
    "ytrain_14y1=pd.DataFrame(data2014_y1.values[:,30])\n",
    "ytest_14y1=pd.DataFrame(pred2014_y1.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_14y1, ytrain_14y1)\n",
    "y_mod_14y1=rfr.predict(xtest_14y1)\n",
    "y_mod_14y1\n",
    "y_mod_14y1=pd.DataFrame(y_mod_14y1)\n",
    "y_mod_14y1.to_csv('pred14_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_14_Fracdeg - data2014_y2 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21681499, 0.14584364, 0.15731195, 0.19295019, 0.19916164,\n",
       "       0.50622218, 0.20078994, 0.18607466, 0.19020126, 0.18723045,\n",
       "       0.3430509 , 0.27075967, 0.19572571, 0.21738633, 0.25958227,\n",
       "       0.22832434, 0.30525597, 0.22871216, 0.163932  , 0.24414953,\n",
       "       0.22940383, 0.22795641, 0.23493079, 0.2460004 , 0.26112404,\n",
       "       0.223119  , 0.18428466, 0.45851646, 0.23677109, 0.21676609,\n",
       "       0.23654991, 0.17745294, 0.27969656, 0.25026456, 0.14277686,\n",
       "       0.19936132, 0.1891313 , 0.17953634, 0.60587096, 0.58944526,\n",
       "       0.25169939, 0.22903744, 0.16781726, 0.17577196, 0.18902153,\n",
       "       0.2191469 , 0.1440068 , 0.17860848, 0.18464839, 0.18873503,\n",
       "       0.20670731, 0.19767281, 0.1619824 , 0.18108446, 0.20435443,\n",
       "       0.19973393, 0.18125671, 0.18332953, 0.17386824, 0.20182288,\n",
       "       0.23984986, 0.29151625, 0.21903892, 0.17220323, 0.18928352,\n",
       "       0.24631206, 0.20049874, 0.24344551, 0.18992169, 0.20162137,\n",
       "       0.19332745, 0.2022874 , 0.18678208, 0.18996872, 0.19738782,\n",
       "       0.17618464, 0.17380352, 0.18563052, 0.18269445, 0.20102085,\n",
       "       0.18912679, 0.14536366, 0.15892006, 0.15993875, 0.19093658,\n",
       "       0.24642357, 0.2448463 , 0.20394218, 0.22134927, 0.22493215,\n",
       "       0.24915002, 0.25950599, 0.21676451, 0.16319064, 0.20245171,\n",
       "       0.20699434, 0.2018972 , 0.21229601, 0.2472334 , 0.21368264,\n",
       "       0.20580888, 0.18589005, 0.16230907, 0.17864492, 0.22035139,\n",
       "       0.13298705, 0.18851372, 0.15351565, 0.20102436, 0.23136926,\n",
       "       0.23818455, 0.18241929, 0.23574818, 0.15326979, 0.14086426,\n",
       "       0.19064098, 0.20622537, 0.14742316, 0.19918267, 0.14985834,\n",
       "       0.20638567, 0.20492307, 0.19573548, 0.17603845, 0.17977908,\n",
       "       0.21308182, 0.20716207, 0.19581262, 0.26006234, 0.18019534,\n",
       "       0.23459419, 0.18508453, 0.18231687, 0.21195609, 0.2046403 ,\n",
       "       0.19650759, 0.13042017, 0.23292659, 0.21286564, 0.1954528 ,\n",
       "       0.23708898, 0.22492016, 0.13918977, 0.2753094 , 0.27421428,\n",
       "       0.21366583, 0.26080149, 0.10199736, 0.21228949, 0.21079121,\n",
       "       0.21410188, 0.22688716, 0.25836282, 0.23049963, 0.22837834,\n",
       "       0.24249965, 0.19074579, 0.17857264, 0.2073926 , 0.22127122,\n",
       "       0.21626744, 0.2051753 , 0.2079439 , 0.21768884, 0.22455218,\n",
       "       0.15381037, 0.33030408, 0.09802465, 0.11124442, 0.19161853,\n",
       "       0.192142  , 0.22116564, 0.1984282 , 0.20203012, 0.19979824,\n",
       "       0.20683443, 0.18073441, 0.1878585 , 0.20278413, 0.1684255 ,\n",
       "       0.20819865, 0.21321368, 0.18748728, 0.20169802, 0.20782419,\n",
       "       0.13647146, 0.1998443 , 0.20903125, 0.15187618, 0.20648998,\n",
       "       0.16983602, 0.21823308, 0.19533663, 0.31283197, 0.1978743 ,\n",
       "       0.20799624, 0.20973576, 0.2146431 , 0.19226347, 0.22753242,\n",
       "       0.25291242, 0.14746666, 0.19388157, 0.20322267, 0.23205006,\n",
       "       0.53159684, 0.18697817, 0.16942469, 0.12269479, 0.15160288,\n",
       "       0.16783399, 0.13046328, 0.20076595, 0.190384  , 0.17295994,\n",
       "       0.17498212, 0.16850507, 0.20086392, 0.17109532, 0.13943171,\n",
       "       0.16113931, 0.24465892, 0.2239954 , 0.25218627, 0.09936046,\n",
       "       0.14772138, 0.1878035 , 0.18487403, 0.21978173, 0.20348907,\n",
       "       0.18057008, 0.19594171, 0.17311015, 0.16119167, 0.17248409,\n",
       "       0.22175959, 0.18330599, 0.19639422, 0.22480414, 0.19433771,\n",
       "       0.25126618, 0.19155954, 0.23878275, 0.20445869, 0.18678617,\n",
       "       0.22888575, 0.17688219, 0.18082414, 0.18679168, 0.17151126,\n",
       "       0.18742906, 0.15454337, 0.16127958, 0.16750761, 0.19350837,\n",
       "       0.18464916, 0.15526868, 0.15389384, 0.1792762 , 0.19411201,\n",
       "       0.16892774, 0.18956456, 0.16903317, 0.14848249, 0.15205236,\n",
       "       0.12029905, 0.13028237, 0.14897123, 0.21493691, 0.21225092,\n",
       "       0.18486207, 0.46603051, 0.18682845, 0.25669177, 0.16420882,\n",
       "       0.18505862, 0.22003893, 0.16899527, 0.20518698, 0.1803271 ,\n",
       "       0.49745781, 0.21110552, 0.22358259, 0.40464414, 0.21970169,\n",
       "       0.22776887, 0.17250679, 0.16136006, 0.25274844, 0.3423331 ,\n",
       "       0.10436124, 0.17823747, 0.16647807, 0.14625001, 0.21000647,\n",
       "       0.15640558, 0.20730806])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y2.csv\")\n",
    "data2014_y2.head(3)\n",
    "data2014_y2.shape\n",
    "pred2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y2.csv\")\n",
    "pred2014_y2.head(3)\n",
    "pred2014_y2.shape\n",
    "xtrain_14y2=pd.DataFrame(data2014_y2.values[:,1:30])\n",
    "xtest_14y2=pd.DataFrame(pred2014_y2.values[:,1:30])\n",
    "ytrain_14y2=pd.DataFrame(data2014_y2.values[:,30])\n",
    "ytest_14y2=pd.DataFrame(pred2014_y2.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_14y2, ytrain_14y2)\n",
    "y_mod_14y2=rfr.predict(xtest_14y2)\n",
    "y_mod_14y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_14_Fracdeg - data2014_y2 - bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y2.csv\")\n",
    "data2014_y2.head(3)\n",
    "data2014_y2.shape\n",
    "pred2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y2.csv\")\n",
    "pred2014_y2.head(3)\n",
    "pred2014_y2.shape\n",
    "xtrain_14y2=pd.DataFrame(data2014_y2.values[:,1:30])\n",
    "xtest_14y2=pd.DataFrame(pred2014_y2.values[:,1:30])\n",
    "ytrain_14y2=pd.DataFrame(data2014_y2.values[:,30])\n",
    "ytest_14y2=pd.DataFrame(pred2014_y2.values[:,30])\n",
    "bingr = BaggingRegressor().fit(xtrain_14y2, ytrain_14y2)\n",
    "y_mod_14y2_1=bingr.predict(xtest_14y2)\n",
    "y_mod_14y2_1\n",
    "y_mod_14y2_1=pd.DataFrame(y_mod_14y2_1)\n",
    "y_mod_14y2_1.to_csv('pred14_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y2.csv\")\n",
    "data2014_y2.head(3)\n",
    "data2014_y2.shape\n",
    "pred2014_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y2.csv\")\n",
    "pred2014_y2.head(3)\n",
    "pred2014_y2.shape\n",
    "xtrain_14y2=pd.DataFrame(data2014_y2.values[:,2:30])\n",
    "xtest_14y2=pd.DataFrame(pred2014_y2.values[:,2:30])\n",
    "ytrain_14y2=pd.DataFrame(data2014_y2.values[:,30])\n",
    "ytest_14y2=pd.DataFrame(pred2014_y2.values[:,30])\n",
    "bingr = BaggingRegressor().fit(xtrain_14y2, ytrain_14y2)\n",
    "y_mod_14y2_1=bingr.predict(xtest_14y2)\n",
    "y_mod_14y2_1\n",
    "y_mod_14y2_1=pd.DataFrame(y_mod_14y2_1)\n",
    "y_mod_14y2_1.to_csv('pred14_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_14_RETPCNT - data2014_y3 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y3.csv\")\n",
    "data2014_y3.head(3)\n",
    "data2014_y3.shape\n",
    "pred2014_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y3.csv\")\n",
    "pred2014_y3.head(3)\n",
    "pred2014_y3.shape\n",
    "xtrain_14y3=pd.DataFrame(data2014_y3.values[:,1:30])\n",
    "xtest_14y3=pd.DataFrame(pred2014_y3.values[:,1:30])\n",
    "ytrain_14y3=pd.DataFrame(data2014_y3.values[:,30])\n",
    "ytest_14y3=pd.DataFrame(pred2014_y3.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_14y3, ytrain_14y3)\n",
    "y_mod_14y3=rfr.predict(xtest_14y3)\n",
    "y_mod_14y3\n",
    "y_mod_14y3=pd.DataFrame(y_mod_14y3)\n",
    "y_mod_14y3.to_csv('pred14_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2014_y3.csv\")\n",
    "data2014_y3.head(3)\n",
    "data2014_y3.shape\n",
    "pred2014_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_14y3.csv\")\n",
    "pred2014_y3.head(3)\n",
    "pred2014_y3.shape\n",
    "xtrain_14y3=pd.DataFrame(data2014_y3.values[:,2:30])\n",
    "xtest_14y3=pd.DataFrame(pred2014_y3.values[:,2:30])\n",
    "ytrain_14y3=pd.DataFrame(data2014_y3.values[:,30])\n",
    "ytest_14y3=pd.DataFrame(pred2014_y3.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_14y3, ytrain_14y3)\n",
    "y_mod_14y3=rfr.predict(xtest_14y3)\n",
    "y_mod_14y3\n",
    "y_mod_14y3=pd.DataFrame(y_mod_14y3)\n",
    "y_mod_14y3.to_csv('pred14_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_15_Chgenrol - data2015_y1 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y1.csv\")\n",
    "data2015_y1.head(3)\n",
    "data2015_y1.shape\n",
    "pred2015_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y1.csv\")\n",
    "pred2015_y1.head(3)\n",
    "pred2015_y1.shape\n",
    "xtrain_15y1=pd.DataFrame(data2015_y1.values[:,1:27])\n",
    "xtest_15y1=pd.DataFrame(pred2015_y1.values[:,1:27])\n",
    "ytrain_15y1=pd.DataFrame(data2015_y1.values[:,27])\n",
    "ytest_15y2=pd.DataFrame(pred2015_y1.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrain_15y1, ytrain_15y1)\n",
    "y_mod_15y1=rfr.predict(xtest_15y1)\n",
    "y_mod_15y1\n",
    "y_mod_15y1=pd.DataFrame(y_mod_15y1)\n",
    "y_mod_15y1.to_csv('pred15_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y1.csv\")\n",
    "data2015_y1.head(3)\n",
    "data2015_y1.shape\n",
    "pred2015_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y1.csv\")\n",
    "pred2015_y1.head(3)\n",
    "pred2015_y1.shape\n",
    "xtrain_15y1=pd.DataFrame(data2015_y1.values[:,2:27])\n",
    "xtest_15y1=pd.DataFrame(pred2015_y1.values[:,2:27])\n",
    "ytrain_15y1=pd.DataFrame(data2015_y1.values[:,27])\n",
    "ytest_15y2=pd.DataFrame(pred2015_y1.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrain_15y1, ytrain_15y1)\n",
    "y_mod_15y1=rfr.predict(xtest_15y1)\n",
    "y_mod_15y1\n",
    "y_mod_15y1=pd.DataFrame(y_mod_15y1)\n",
    "y_mod_15y1.to_csv('pred15_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_15_FRANC - data2015_y2 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2042984 , 0.13037048, 0.17045888, 0.15699265, 0.21437573,\n",
       "       0.47179022, 0.21562399, 0.20538084, 0.21237699, 0.18572644,\n",
       "       0.25171926, 0.26219824, 0.17877383, 0.19271979, 0.24917366,\n",
       "       0.21470626, 0.25632733, 0.3214088 , 0.23340398, 0.19755978,\n",
       "       0.26209793, 0.25963705, 0.20609328, 0.26983576, 0.23547269,\n",
       "       0.20906157, 0.18836425, 0.28466339, 0.22299197, 0.24031134,\n",
       "       0.23726747, 0.18791667, 0.26995322, 0.22959133, 0.17015922,\n",
       "       0.20867531, 0.19262292, 0.19383884, 0.26708033, 0.33122183,\n",
       "       0.24030924, 0.23754411, 0.17919501, 0.15952027, 0.17312803,\n",
       "       0.22594934, 0.14398364, 0.14447908, 0.18189687, 0.17106881,\n",
       "       0.22032186, 0.19971385, 0.1597488 , 0.18222397, 0.21677957,\n",
       "       0.2071422 , 0.22090784, 0.19501844, 0.17700939, 0.20561432,\n",
       "       0.23502079, 0.27543098, 0.22117257, 0.1732575 , 0.19194211,\n",
       "       0.22238296, 0.21845847, 0.22229722, 0.19587801, 0.18532036,\n",
       "       0.22214339, 0.21732298, 0.19639167, 0.25414084, 0.17953884,\n",
       "       0.19115717, 0.18495185, 0.16190383, 0.19274127, 0.20645371,\n",
       "       0.19252264, 0.19969108, 0.1618034 , 0.15523555, 0.11238412,\n",
       "       0.23382491, 0.22529679, 0.20513426, 0.224568  , 0.2454357 ,\n",
       "       0.25498184, 0.23243685, 0.18725452, 0.17544503, 0.23327056,\n",
       "       0.2094342 , 0.20989288, 0.20696879, 0.25049676, 0.23884961,\n",
       "       0.21651332, 0.21297372, 0.18416617, 0.1836901 , 0.2428864 ,\n",
       "       0.14096346, 0.18749934, 0.1677652 , 0.22391116, 0.17387169,\n",
       "       0.23025007, 0.1773876 , 0.24221841, 0.14446075, 0.15976182,\n",
       "       0.19322142, 0.19552468, 0.16569386, 0.21280451, 0.19958334,\n",
       "       0.20995796, 0.22549774, 0.21339634, 0.18488928, 0.18627875,\n",
       "       0.21638991, 0.20090631, 0.21314381, 0.24655662, 0.18121896,\n",
       "       0.20637182, 0.17717621, 0.22349508, 0.20758979, 0.20970994,\n",
       "       0.20549094, 0.20549605, 0.24560907, 0.23422408, 0.20723567,\n",
       "       0.25387711, 0.23968654, 0.11521825, 0.11944292, 0.28578809,\n",
       "       0.24722559, 0.27533051, 0.09732893, 0.21590801, 0.20604594,\n",
       "       0.20335385, 0.19751875, 0.27373173, 0.22396903, 0.21206599,\n",
       "       0.24407559, 0.19929245, 0.18961877, 0.18501543, 0.2338845 ,\n",
       "       0.21394035, 0.20686918, 0.20654172, 0.21845445, 0.22357567,\n",
       "       0.07032706, 0.20248904, 0.05893009, 0.17136126, 0.18515031,\n",
       "       0.18391616, 0.21481322, 0.1799545 , 0.18596306, 0.23394761,\n",
       "       0.17623744, 0.20584925, 0.18328832, 0.21108039, 0.19855325,\n",
       "       0.25840417, 0.18873003, 0.21638465, 0.19400558, 0.22963044,\n",
       "       0.11832198, 0.19429406, 0.21142462, 0.16416848, 0.19852308,\n",
       "       0.18373791, 0.21553218, 0.20017195, 0.38919605, 0.21138549,\n",
       "       0.21901332, 0.22676878, 0.19049059, 0.23393822, 0.24348971,\n",
       "       0.26097963, 0.16190749, 0.20675375, 0.21900897, 0.23075668,\n",
       "       0.53934637, 0.19340876, 0.14233992, 0.15887277, 0.28678343,\n",
       "       0.17993597, 0.26620663, 0.22673971, 0.22541658, 0.18329712,\n",
       "       0.14638826, 0.17958969, 0.18381042, 0.18265725, 0.14897986,\n",
       "       0.14982893, 0.22347924, 0.2200951 , 0.1748261 , 0.1151816 ,\n",
       "       0.13482937, 0.20729389, 0.18807242, 0.23345788, 0.2389237 ,\n",
       "       0.16319748, 0.19407064, 0.23735805, 0.17403866, 0.18606985,\n",
       "       0.20409645, 0.18715118, 0.18433755, 0.23635927, 0.183893  ,\n",
       "       0.23595264, 0.18763357, 0.22255233, 0.21193435, 0.20334491,\n",
       "       0.24040106, 0.17735735, 0.18418305, 0.21483278, 0.17809012,\n",
       "       0.21468425, 0.16566638, 0.12953377, 0.21086847, 0.19163814,\n",
       "       0.18864051, 0.16099364, 0.1228504 , 0.1887338 , 0.21552745,\n",
       "       0.18156173, 0.20674612, 0.18432558, 0.15210149, 0.23638951,\n",
       "       0.1207972 , 0.12668115, 0.05203869, 0.28414686, 0.22008571,\n",
       "       0.19830075, 0.36294027, 0.19101938, 0.24429166, 0.16275666,\n",
       "       0.19834183, 0.20367909, 0.22886731, 0.19378608, 0.19794668,\n",
       "       0.36687852, 0.17915657, 0.17942373, 0.21622109, 0.22574968,\n",
       "       0.23895883, 0.19192603, 0.15149697, 0.22059221, 0.12192365,\n",
       "       0.1144472 , 0.15490092, 0.17166596, 0.16485457, 0.18019872,\n",
       "       0.16524427, 0.22791786])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y2.csv\")\n",
    "data2015_y2.head(3)\n",
    "data2015_y2.shape\n",
    "pred2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y2.csv\")\n",
    "pred2015_y2.head(3)\n",
    "pred2015_y2.shape\n",
    "xtrain_15y2=pd.DataFrame(data2015_y2.values[:,1:27])\n",
    "xtest_15y2=pd.DataFrame(pred2015_y2.values[:,1:27])\n",
    "ytrain_15y2=pd.DataFrame(data2015_y2.values[:,27])\n",
    "ytest_15y2=pd.DataFrame(pred2015_y2.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrain_15y2, ytrain_15y2)\n",
    "y_mod_15y2=rfr.predict(xtest_15y2)\n",
    "y_mod_15y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_15_fracde - data2015_y2 - bagging regresorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y2.csv\")\n",
    "data2015_y2.head(3)\n",
    "data2015_y2.shape\n",
    "pred2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y2.csv\")\n",
    "pred2015_y2.head(3)\n",
    "pred2015_y2.shape\n",
    "xtrain_15y2=pd.DataFrame(data2015_y2.values[:,1:27])\n",
    "xtest_15y2=pd.DataFrame(pred2015_y2.values[:,1:27])\n",
    "ytrain_15y2=pd.DataFrame(data2015_y2.values[:,27])\n",
    "ytest_15y2=pd.DataFrame(pred2015_y2.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_15y2, ytrain_15y2)\n",
    "y_mod_15y2_1=bingr.predict(xtest_15y2)\n",
    "y_mod_15y2_1\n",
    "y_mod_15y2_1=pd.DataFrame(y_mod_15y2_1)\n",
    "y_mod_15y2_1.to_csv('pred15_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y2.csv\")\n",
    "data2015_y2.head(3)\n",
    "data2015_y2.shape\n",
    "pred2015_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y2.csv\")\n",
    "pred2015_y2.head(3)\n",
    "pred2015_y2.shape\n",
    "xtrain_15y2=pd.DataFrame(data2015_y2.values[:,2:27])\n",
    "xtest_15y2=pd.DataFrame(pred2015_y2.values[:,2:27])\n",
    "ytrain_15y2=pd.DataFrame(data2015_y2.values[:,27])\n",
    "ytest_15y2=pd.DataFrame(pred2015_y2.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_15y2, ytrain_15y2)\n",
    "y_mod_15y2_1=bingr.predict(xtest_15y2)\n",
    "y_mod_15y2_1\n",
    "y_mod_15y2_1=pd.DataFrame(y_mod_15y2_1)\n",
    "y_mod_15y2_1.to_csv('pred15_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_15_retpcnt - data2015_y3 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88.6, 21.2, 58.3, 53.6, 60.2, 67.2, 84.2, 59.7, 82.8, 60. , 38.5,\n",
       "       96.7, 79.3, 76.6, 91.7, 62. , 53.4, 38.4, 77.3, 52.9, 80. , 79. ,\n",
       "       82.6, 84.4, 93.9, 56. , 77.4, 49.2, 68.7, 83.8, 86.5, 75.3, 97.8,\n",
       "       83. , 30.1, 79.6, 73.3, 58.8, 25.1, 28.3, 87.3, 91.9, 29.9, 31.1,\n",
       "       61.7, 28.5, 24.4, 46.8, 22. , 73.3, 23.7, 79.5, 25.1, 34.3, 87.2,\n",
       "       74.8, 62.5, 60.5, 32.4, 61.6, 86. , 96.8, 79.3, 78.3, 61.4, 66.1,\n",
       "       75.3, 91.4, 62.2, 61.7, 74.5, 87.9, 63.2, 37.4, 56.8, 34.7, 50.3,\n",
       "       47.7, 39.4, 58.1, 35.9, 40.4, 65.4, 45.7, 48. , 84.2, 91.3, 72.8,\n",
       "       73.5, 81.7, 98.2, 94.2, 83.1, 76.5, 74.6, 87.2, 86.8, 75.1, 93.5,\n",
       "       88.7, 82.2, 82. , 75.1, 36.6, 84.8, 68.8, 75. , 72.4, 64.8, 48.6,\n",
       "       91. , 28.8, 85.5, 42.9, 33.8, 84.1, 49.9, 65.1, 50.7, 45. , 87.5,\n",
       "       86.6, 77. , 74.5, 44.7, 85.3, 69.1, 34. , 57.8, 61.2, 39.5, 44.2,\n",
       "       76.9, 76.3, 76.1, 86.6, 22.1, 80.5, 87.1, 61. , 77.3, 91.2, 65.3,\n",
       "       29. , 97.4, 81.8, 86.3, 37.9, 34. , 42.9, 40.9, 34.7, 92.1, 65.7,\n",
       "       78.4, 84.3, 38.8, 38.2, 46.3, 90.3, 86.7, 81.4, 45.2, 72.4, 71.9,\n",
       "       43.1, 32.1, 49.3, 50.1, 75.1, 76.6, 92.5, 23. , 24.3, 76.3, 22.1,\n",
       "       23.5, 22. , 85.9, 77.7, 86.2, 76.5, 34.9, 38.2, 72.2, 45.5, 51.4,\n",
       "       92. , 33.5, 75.5, 49.2, 65.4, 74.2, 37.1, 78.9, 77.2, 66.6, 62.1,\n",
       "       47.9, 82.2, 94.8, 57.8, 78.8, 63.8, 90.7, 34.6, 81. , 76.2, 79. ,\n",
       "       40.7, 60. , 48.2, 91.2, 62.7, 54.2, 61.1, 22.7, 30.5, 26.3, 15.7,\n",
       "       72.7, 81.2, 40.8, 56.5, 21.1, 19.9, 60. , 60.7, 89.3, 89.5, 22. ,\n",
       "       33.2, 72.5, 63.8, 35. , 85.4, 61.3, 46.8, 85.3, 79.6, 92.3, 76.4,\n",
       "       87.6, 88.3, 68. , 86. , 60.3, 50.1, 59.6, 42.7, 80.9, 57.2, 34.8,\n",
       "       76.2, 81.9, 78.3, 55.2, 63.2, 79.1, 29.4, 61.8, 62.6, 62.3, 49.6,\n",
       "       61. , 46.9, 47.4, 48.2, 45.2, 78.1, 83.3, 48.1, 78.1, 97.2, 42.9,\n",
       "       81.7, 78.8, 52.9, 17. , 44.4, 44.3, 43.1, 42.8, 37.9, 24.1, 51.2,\n",
       "       33.4, 14.6, 28.2, 48.7, 41. , 55.2, 29.6, 38.4, 23. , 42.4, 68.1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y3.csv\")\n",
    "data2015_y3.head(3)\n",
    "data2015_y3.shape\n",
    "pred2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y3.csv\")\n",
    "pred2015_y3.head(3)\n",
    "pred2015_y3.shape\n",
    "xtrain_15y3=pd.DataFrame(data2015_y3.values[:,1:27])\n",
    "xtest_15y3=pd.DataFrame(pred2015_y3.values[:,1:27])\n",
    "ytrain_15y3=pd.DataFrame(data2015_y3.values[:,27])\n",
    "ytest_15y3=pd.DataFrame(pred2015_y3.values[:,27])\n",
    "rfr = RandomForestRegressor().fit(xtrain_15y3, ytrain_15y3)\n",
    "y_mod_15y3=rfr.predict(xtest_15y3)\n",
    "y_mod_15y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_15_retpcnt- data2015_y3 - bagging regresorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y3.csv\")\n",
    "data2015_y3.head(3)\n",
    "data2015_y3.shape\n",
    "pred2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y3.csv\")\n",
    "pred2015_y3.head(3)\n",
    "pred2015_y3.shape\n",
    "xtrain_15y3=pd.DataFrame(data2015_y3.values[:,1:27])\n",
    "xtest_15y3=pd.DataFrame(pred2015_y3.values[:,1:27])\n",
    "ytrain_15y3=pd.DataFrame(data2015_y3.values[:,27])\n",
    "ytest_15y3=pd.DataFrame(pred2015_y3.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_15y3, ytrain_15y3)\n",
    "y_mod_15y3_1=bingr.predict(xtest_15y3)\n",
    "y_mod_15y3_1\n",
    "y_mod_15y3_1=pd.DataFrame(y_mod_15y3_1)\n",
    "y_mod_15y3_1.to_csv('pred15_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2015_y3.csv\")\n",
    "data2015_y3.head(3)\n",
    "data2015_y3.shape\n",
    "pred2015_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_15y3.csv\")\n",
    "pred2015_y3.head(3)\n",
    "pred2015_y3.shape\n",
    "xtrain_15y3=pd.DataFrame(data2015_y3.values[:,2:27])\n",
    "xtest_15y3=pd.DataFrame(pred2015_y3.values[:,2:27])\n",
    "ytrain_15y3=pd.DataFrame(data2015_y3.values[:,27])\n",
    "ytest_15y3=pd.DataFrame(pred2015_y3.values[:,27])\n",
    "bingr = BaggingRegressor().fit(xtrain_15y3, ytrain_15y3)\n",
    "y_mod_15y3_1=bingr.predict(xtest_15y3)\n",
    "y_mod_15y3_1\n",
    "y_mod_15y3_1=pd.DataFrame(y_mod_15y3_1)\n",
    "y_mod_15y3_1.to_csv('pred15_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_16_Chgenrol - data2016_y1 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y1.csv\")\n",
    "data2016_y1.head(3)\n",
    "data2016_y1.shape\n",
    "pred2016_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y1.csv\")\n",
    "pred2016_y1.head(3)\n",
    "pred2016_y1.shape\n",
    "xtrain_16y1=pd.DataFrame(data2016_y1.values[:,1:30])\n",
    "xtest_16y1=pd.DataFrame(pred2016_y1.values[:,1:30])\n",
    "ytrain_16y1=pd.DataFrame(data2016_y1.values[:,30])\n",
    "ytest_16y1=pd.DataFrame(pred2016_y1.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_16y1, ytrain_16y1)\n",
    "y_mod_16y1=rfr.predict(xtest_16y1)\n",
    "y_mod_16y1\n",
    "y_mod_16y1=pd.DataFrame(y_mod_16y1)\n",
    "y_mod_16y1.to_csv('pred16_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y1.csv\")\n",
    "data2016_y1.head(3)\n",
    "data2016_y1.shape\n",
    "pred2016_y1 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y1.csv\")\n",
    "pred2016_y1.head(3)\n",
    "pred2016_y1.shape\n",
    "xtrain_16y1=pd.DataFrame(data2016_y1.values[:,2:30])\n",
    "xtest_16y1=pd.DataFrame(pred2016_y1.values[:,2:30])\n",
    "ytrain_16y1=pd.DataFrame(data2016_y1.values[:,30])\n",
    "ytest_16y1=pd.DataFrame(pred2016_y1.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_16y1, ytrain_16y1)\n",
    "y_mod_16y1=rfr.predict(xtest_16y1)\n",
    "y_mod_16y1\n",
    "y_mod_16y1=pd.DataFrame(y_mod_16y1)\n",
    "y_mod_16y1.to_csv('pred16_y1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_16_fracdegre - data2016_y2 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00259816, 1.01795324, 1.03850404, 0.95297124, 0.91808606,\n",
       "       1.01773419, 1.08374879, 1.13768541, 1.03072891, 1.03671494,\n",
       "       0.98056431, 0.81408   , 1.02002812, 1.08898405, 1.02789765,\n",
       "       1.08509958, 1.14302848, 1.03662915, 1.02843536, 0.98210339,\n",
       "       0.84402285, 0.99390783, 1.12106909, 0.95362905, 1.01436194,\n",
       "       0.97825889, 1.06622248, 0.95295551, 0.98557532, 1.0109104 ,\n",
       "       0.98512795, 0.97290932, 0.94431247, 0.93688728, 1.08251148,\n",
       "       0.98212679, 1.08242834, 1.02180779, 0.96858141, 1.04915108,\n",
       "       1.02398875, 0.99129572, 1.10804864, 1.06982296, 1.06307808,\n",
       "       0.9653006 , 1.00595637, 0.95148243, 1.00434839, 0.93126264,\n",
       "       1.089131  , 1.03081442, 1.0178952 , 1.0181789 , 1.0133675 ,\n",
       "       0.97911518, 1.01930111, 1.08150504, 1.00593301, 0.97392486,\n",
       "       1.02878817, 1.01246388, 0.97455238, 1.01391817, 1.01564724,\n",
       "       1.01539104, 0.94569501, 0.99973508, 1.0079019 , 0.83232368,\n",
       "       0.98822676, 0.96995038, 1.05204857, 0.96650326, 1.04625571,\n",
       "       1.02607751, 1.01344925, 0.94180472, 1.06757751, 0.9809066 ,\n",
       "       1.05465339, 1.02897312, 1.08751282, 1.01324619, 1.02404237,\n",
       "       1.01858821, 1.02947275, 1.01886454, 1.01420356, 1.04114631,\n",
       "       0.84768848, 0.95419848, 1.08272556, 1.01566284, 1.00047402,\n",
       "       1.00649604, 0.99553079, 1.0084216 , 1.01859468, 1.00306765,\n",
       "       0.99072723, 0.98932358, 1.01369609, 0.96946801, 1.00833473,\n",
       "       1.14413074, 1.11262684, 0.9395988 , 1.09719314, 1.00016833,\n",
       "       1.00343922, 1.07650176, 1.00320719, 1.03067838, 1.09855223,\n",
       "       1.01372794, 1.05630327, 1.16673223, 1.03353727, 0.85137821,\n",
       "       1.00848053, 1.08733113, 1.09560671, 1.02180256, 1.06549424,\n",
       "       1.06803629, 1.00400799, 1.03190673, 1.02218581, 1.06667724,\n",
       "       1.09720754, 0.95999511, 0.98088719, 0.99493874, 0.95165254,\n",
       "       1.06134471, 0.90640847, 1.0033029 , 1.00218654, 0.97880874,\n",
       "       1.07299007, 1.00787351, 0.82369934, 1.0487757 , 0.88267128,\n",
       "       0.98629314, 0.84629767, 0.95290223, 1.04692806, 1.01601617,\n",
       "       1.02527258, 1.02822186, 1.01033697, 0.99207332, 1.00339363,\n",
       "       1.01967045, 0.98049921, 1.05125113, 1.02365808, 1.04319389,\n",
       "       0.99046153, 1.04509069, 0.98753168, 1.0087958 , 0.96283314,\n",
       "       1.03806404, 1.05336166, 1.04544673, 1.02446167, 1.00826694,\n",
       "       0.97892052, 1.00944074, 0.95555329, 0.97440675, 0.98616583,\n",
       "       0.99921237, 0.96179047, 1.00796315, 1.00701975, 0.99315986,\n",
       "       1.04681257, 1.06213962, 1.00112406, 1.02935674, 0.98934368,\n",
       "       1.08780831, 0.89757889, 1.00438625, 1.06535327, 1.04804523,\n",
       "       0.97935763, 1.00399701, 1.03652995, 1.04420573, 1.07407613,\n",
       "       0.98610785, 1.00568776, 1.00421622, 0.99593801, 0.98803125,\n",
       "       1.01913294, 0.90068724, 1.0140166 , 1.05883721, 1.01691955,\n",
       "       0.95874222, 1.02552459, 0.97424138, 0.97775844, 1.06951624,\n",
       "       0.98862255, 1.09497042, 0.99926613, 1.01947951, 1.00191434,\n",
       "       1.07965279, 1.05614865, 0.97285185, 0.99730487, 1.0157128 ,\n",
       "       1.01331597, 1.02225604, 1.12917317, 1.022681  , 0.96117576,\n",
       "       0.97833173, 1.04035251, 1.00407431, 1.01519895, 1.00839958,\n",
       "       1.0476632 , 1.09932517, 1.01309288, 1.13795761, 1.01788705,\n",
       "       1.00790053, 1.09729864, 1.04601787, 1.052906  , 1.12568729,\n",
       "       1.09522264, 1.08779791, 1.02329252, 0.96978847, 1.00599009,\n",
       "       1.00093882, 1.01880864, 1.02922301, 0.99851533, 1.01616301,\n",
       "       1.03599723, 0.97024788, 0.95472235, 0.98527476, 1.0722916 ,\n",
       "       1.03673046, 1.01247754, 0.97682379, 1.02566719, 1.04620207,\n",
       "       1.10199833, 0.99850122, 0.98211004, 1.07560619, 1.06771188,\n",
       "       0.99652951, 0.99679582, 1.04520684, 0.89487197, 1.00979578,\n",
       "       1.05531092, 0.98088878, 1.01975498, 0.99521645, 1.02698403,\n",
       "       1.08340293, 1.01208856, 0.95750912, 0.94299209, 1.00414941,\n",
       "       1.07231881, 1.00969504, 1.05109121, 1.05192395, 1.01669034,\n",
       "       1.10917435, 0.94124905, 1.00330984, 0.98112119, 1.20112435,\n",
       "       0.98064164, 0.91941895, 0.94431059, 0.93672369, 0.79093808,\n",
       "       1.03012969, 0.98381227])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y1.csv\")\n",
    "data2016_y2.head(3)\n",
    "data2016_y2.shape\n",
    "pred2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y1.csv\")\n",
    "pred2016_y2.head(3)\n",
    "pred2016_y2.shape\n",
    "xtrain_16y2=pd.DataFrame(data2016_y2.values[:,1:30])\n",
    "xtest_16y2=pd.DataFrame(pred2016_y2.values[:,1:30])\n",
    "ytrain_16y2=pd.DataFrame(data2016_y2.values[:,30])\n",
    "ytest_16y2=pd.DataFrame(pred2016_y2.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_16y2, ytrain_16y2)\n",
    "y_mod_16y2=rfr.predict(xtest_16y2)\n",
    "y_mod_16y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_16_fracdegre - data2016_y2 - bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y1.csv\")\n",
    "data2016_y2.head(3)\n",
    "data2016_y2.shape\n",
    "pred2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y1.csv\")\n",
    "pred2016_y2.head(3)\n",
    "pred2016_y2.shape\n",
    "xtrain_16y2=pd.DataFrame(data2016_y2.values[:,1:30])\n",
    "xtest_16y2=pd.DataFrame(pred2016_y2.values[:,1:30])\n",
    "ytrain_16y2=pd.DataFrame(data2016_y2.values[:,30])\n",
    "ytest_16y2=pd.DataFrame(pred2016_y2.values[:,30])\n",
    "bingr = BaggingRegressor().fit(xtrain_16y2, ytrain_16y2)\n",
    "y_mod_16y2_1=bingr.predict(xtest_16y2)\n",
    "y_mod_16y2_1\n",
    "y_mod_16y2_1=pd.DataFrame(y_mod_16y2_1)\n",
    "y_mod_16y2_1.to_csv('pred16_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y1.csv\")\n",
    "data2016_y2.head(3)\n",
    "data2016_y2.shape\n",
    "pred2016_y2 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y1.csv\")\n",
    "pred2016_y2.head(3)\n",
    "pred2016_y2.shape\n",
    "xtrain_16y2=pd.DataFrame(data2016_y2.values[:,2:30])\n",
    "xtest_16y2=pd.DataFrame(pred2016_y2.values[:,2:30])\n",
    "ytrain_16y2=pd.DataFrame(data2016_y2.values[:,30])\n",
    "ytest_16y2=pd.DataFrame(pred2016_y2.values[:,30])\n",
    "bingr = BaggingRegressor().fit(xtrain_16y2, ytrain_16y2)\n",
    "y_mod_16y2_1=bingr.predict(xtest_16y2)\n",
    "y_mod_16y2_1\n",
    "y_mod_16y2_1=pd.DataFrame(y_mod_16y2_1)\n",
    "y_mod_16y2_1.to_csv('pred16_y2.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_16_fracdegre - data2016_y3 - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y3.csv\")\n",
    "data2016_y3.head(3)\n",
    "data2016_y3.shape\n",
    "pred2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y3.csv\")\n",
    "pred2016_y3.head(3)\n",
    "pred2016_y3.shape\n",
    "xtrain_16y3=pd.DataFrame(data2016_y3.values[:,1:30])\n",
    "xtest_16y3=pd.DataFrame(pred2016_y3.values[:,1:30])\n",
    "ytrain_16y3=pd.DataFrame(data2016_y3.values[:,30])\n",
    "ytest_16y3=pd.DataFrame(pred2016_y3.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_16y3, ytrain_16y3)\n",
    "y_mod_16y3=rfr.predict(xtest_16y3)\n",
    "y_mod_16y3\n",
    "y_mod_16y3=pd.DataFrame(y_mod_16y3)\n",
    "y_mod_16y3.to_csv('pred16_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y3.csv\")\n",
    "data2016_y3.head(3)\n",
    "data2016_y3.shape\n",
    "pred2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y3.csv\")\n",
    "pred2016_y3.head(3)\n",
    "pred2016_y3.shape\n",
    "xtrain_16y3=pd.DataFrame(data2016_y3.values[:,2:30])\n",
    "xtest_16y3=pd.DataFrame(pred2016_y3.values[:,2:30])\n",
    "ytrain_16y3=pd.DataFrame(data2016_y3.values[:,30])\n",
    "ytest_16y3=pd.DataFrame(pred2016_y3.values[:,30])\n",
    "rfr = RandomForestRegressor().fit(xtrain_16y3, ytrain_16y3)\n",
    "y_mod_16y3=rfr.predict(xtest_16y3)\n",
    "y_mod_16y3\n",
    "y_mod_16y3=pd.DataFrame(y_mod_16y3)\n",
    "y_mod_16y3.to_csv('pred16_y3.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predic_16_fracdegre - data2016_y3 - bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88.6, 23.1, 59.8, 35.3, 16.3, 25.9, 70.4, 33.7, 79.2, 64.4, 23.2,\n",
       "       86.5, 53.9, 53.8, 90. , 64.1, 26.9, 18.5, 38.6, 26.7, 46.5, 86.2,\n",
       "       77.8, 71.8, 92.5, 39.3, 46. , 25.7, 63.1, 65.4, 68.9, 77.2, 96.4,\n",
       "       65.7, 25. , 47.6, 75. , 61.8, 21.2, 20.4, 85.5, 89.3, 21.6, 33.4,\n",
       "       32.3, 33. , 33.7, 37.3, 34.9, 55. , 24. , 53.2, 30.3, 56.5, 74.8,\n",
       "       69.9, 27.6, 31.9, 28.1, 62.1, 57.8, 85.9, 49.9, 57.2, 63.7, 70.4,\n",
       "       76.8, 88.9, 60. , 62.6, 73.9, 66. , 64.4, 25.7, 56.9, 28.4, 35.7,\n",
       "       58.3, 27.2, 60.1, 26.1, 24.6, 34.9, 31.1, 35.3, 67. , 89.3, 82.8,\n",
       "       51.5, 53.8, 86.3, 69.3, 67.5, 75.5, 70.7, 85.2, 75.4, 70.6, 93.1,\n",
       "       77.8, 79.4, 53. , 68.1, 25.2, 82.6, 53.5, 74.6, 51.2, 59.9, 13.6,\n",
       "       82.6, 51. , 86.9, 35.9, 27.7, 51.9, 50. , 49.5, 30.1, 51. , 77.9,\n",
       "       90.8, 60.7, 71.9, 54.4, 86.2, 60.3, 61.2, 63.1, 59.1, 57.9, 21.7,\n",
       "       59.6, 61.3, 59.7, 86.7, 23.1, 80.6, 66. , 63.2, 42.7, 60.4, 25.6,\n",
       "       16.5, 86.5, 59.7, 87.9, 25.9, 11.9, 58. , 19.9, 24. , 91.5, 30.2,\n",
       "       61.7, 84.4, 28.3, 29.1, 38.2, 81.6, 87.6, 64.6, 60.9, 75.1, 72.7,\n",
       "       18.2, 23.3, 21.4, 12.9, 62.6, 51. , 88.5, 32.8, 34.2, 73.2, 32.7,\n",
       "       33. , 34.1, 84.6, 59.4, 82.2, 61.7, 62.3, 35.6, 71.7, 13. , 34.2,\n",
       "       89. , 33.4, 61.6, 35.6, 72.6, 73.2, 20.6, 52.1, 52.7, 54.6, 61.6,\n",
       "       38.3, 62.9, 92.8, 72.5, 69.4, 69.7, 89.9, 21.3, 73.9, 72.5, 54.3,\n",
       "       20.5, 22.2, 50.5, 60. , 60.9, 56.8, 50.4, 23.4, 34.5, 57.9, 33.6,\n",
       "       61. , 77.3, 62.2, 59.6, 35.4, 36.7, 59.6, 63.1, 89.7, 89.1, 29.4,\n",
       "       36.1, 54.8, 70.7, 33.2, 65.6, 27.7, 33.8, 75.1, 63.1, 89.5, 55.3,\n",
       "       89.5, 75.1, 62.9, 67. , 61.5, 63.1, 59.6, 37.7, 66.3, 27.8, 15.2,\n",
       "       30.3, 59.8, 81.3, 20.4, 34.9, 60.1, 18.2, 61.6, 63.4, 55. , 25.7,\n",
       "       22.2, 22.6, 21.4, 23.8, 14.7, 54.3, 80.5, 25.4, 69.9, 95.9, 21. ,\n",
       "       56.5, 58.5, 27.4, 22.7, 20.6, 18.4, 29. , 30.2, 15.3, 19.9, 23.7,\n",
       "       16.6, 16.9, 22.5, 21.6, 15.8, 15.8, 22.6, 17.3, 15.2, 15.8, 65.4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/data2016_y3.csv\")\n",
    "data2016_y3.head(3)\n",
    "data2016_y3.shape\n",
    "pred2016_y3 = pd.read_csv(\"https://raw.githubusercontent.com/vigneshjmurali/Data-Science-Comp/master/Imputed/prediction_16y3.csv\")\n",
    "pred2016_y3.head(3)\n",
    "pred2016_y3.shape\n",
    "xtrain_16y3=pd.DataFrame(data2016_y3.values[:,1:30])\n",
    "xtest_16y3=pd.DataFrame(pred2016_y3.values[:,1:30])\n",
    "ytrain_16y3=pd.DataFrame(data2016_y3.values[:,30])\n",
    "ytest_16y3=pd.DataFrame(pred2016_y3.values[:,30])\n",
    "bingr = BaggingRegressor().fit(xtrain_16y3, ytrain_16y3)\n",
    "y_mod_16y3_1=bingr.predict(xtest_16y3)\n",
    "y_mod_16y3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
